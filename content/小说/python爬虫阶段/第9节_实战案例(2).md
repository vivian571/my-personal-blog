---
title: "第9节_实战案例(2)"
slug: "第9节_实战案例(2)"
date: "2025-04-24T02:48:37.647732+00:00"
---

# 第9节：实战案例(2)

## 学习目标

- **<font color="red">掌握获取某个城市7天天气信息的爬取方法</font>**
- **<font color="blue">学习处理动态加载内容的技巧</font>**
- **<font color="green">理解数据可视化在爬虫项目中的应用</font>**
- **<font color="purple">掌握多页面数据爬取与整合的方法</font>**
- **<font color="orange">学习爬虫项目的完整开发流程</font>**

## 知识点

### 天气网站分析

- **<font color="red">网站结构特点</font>**：
  - 页面布局
  - 数据加载方式
  - URL规律
- **<font color="blue">数据元素定位</font>**：
  - 日期信息
  - 温度数据
  - 天气状况
  - 风向风力
- **<font color="green">反爬机制识别</font>**：
  - 请求频率限制
  - User-Agent检测
  - Cookie验证

### 数据爬取策略

- **<font color="red">城市编码获取</font>**：
  - 城市名称与编码映射
  - 编码规则分析
- **<font color="blue">请求构造</font>**：
  - 参数设置
  - Headers配置
  - 请求频率控制
- **<font color="green">异常处理</font>**：
  - 网络错误处理
  - 数据缺失处理
  - 重试机制

### 数据处理与分析

- **<font color="red">数据清洗</font>**：
  - 去除无用字符
  - 数据格式统一
  - 缺失值处理
- **<font color="blue">数据结构化</font>**：
  - 日期-天气映射
  - 温度数据提取
  - 天气状况分类
- **<font color="green">数据可视化</font>**：
  - 温度变化曲线
  - 天气状况统计
  - 多城市数据对比

## 典型示例

### 获取城市天气数据

```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import matplotlib.pyplot as plt

# 设置中文字体
plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

# 设置请求头
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
}

# 获取城市天气数据
def get_weather_data(city_code):
    url = f'http://www.weather.com.cn/weather/{city_code}.shtml'
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'  # 确保中文正常显示
        
        if response.status_code == 200:
            return response.text
        else:
            print(f"请求失败: {response.status_code}")
            return None
    except Exception as e:
        print(f"请求异常: {e}")
        return None

# 解析天气数据
def parse_weather_data(html):
    if not html:
        return []
    
    soup = BeautifulSoup(html, 'html.parser')
    weather_list = []
    
    # 定位7天天气数据
    weather_divs = soup.select('div.c7d > ul.t.clearfix > li')
    
    for div in weather_divs:
        try:
            # 提取日期
            date = div.select_one('h1').text
            
            # 提取天气状况
            weather = div.select_one('p.wea').text
            
            # 提取温度范围
            temp_range = div.select_one('p.tem').text.strip()
            
            # 提取风向
            wind = div.select_one('p.win > i').text
            
            # 存储天气信息
            weather_info = {
                'date': date,
                'weather': weather,
                'temp_range': temp_range,
                'wind': wind
            }
            
            weather_list.append(weather_info)
        except Exception as e:
            print(f"解析数据异常: {e}")
    
    return weather_list

# 处理温度数据
def process_temperature(weather_list):
    for item in weather_list:
        temp_text = item['temp_range']
        # 分离最高温和最低温
        temps = temp_text.replace('℃', '').split('/')
        
        if len(temps) == 2:
            max_temp = temps[0].strip()
            min_temp = temps[1].strip()
        else:
            # 如果只有一个温度值
            max_temp = temp_text.replace('℃', '').strip()
            min_temp = max_temp
        
        # 转换为数字
        try:
            item['max_temp'] = int(max_temp)
        except:
            item['max_temp'] = None
            
        try:
            item['min_temp'] = int(min_temp)
        except:
            item['min_temp'] = None
    
    return weather_list

# 可视化天气数据
def visualize_weather(weather_list, city_name):
    if not weather_list:
        print("没有数据可视化")
        return
    
    # 准备数据
    dates = [item['date'] for item in weather_list]
    max_temps = [item.get('max_temp') for item in weather_list]
    min_temps = [item.get('min_temp') for item in weather_list]
    
    # 过滤掉None值
    valid_dates = []
    valid_max_temps = []
    valid_min_temps = []
    
    for i in range(len(dates)):
        if max_temps[i] is not None and min_temps[i] is not None:
            valid_dates.append(dates[i])
            valid_max_temps.append(max_temps[i])
            valid_min_temps.append(min_temps[i])
    
    # 绘制温度变化图
    plt.figure(figsize=(12, 6))
    plt.plot(valid_dates, valid_max_temps, 'ro-', label='最高温')
    plt.plot(valid_dates, valid_min_temps, 'bo-', label='最低温')
    
    plt.title(f'{city_name}未来7天天气预报')
    plt.xlabel('日期')
    plt.ylabel('温度(℃)')
    plt.legend()
    plt.grid(True)
    plt.xticks(rotation=45)
    
    # 添加数据标签
    for i in range(len(valid_dates)):
        plt.text(i, valid_max_temps[i], f'{valid_max_temps[i]}℃', ha='center', va='bottom')
        plt.text(i, valid_min_temps[i], f'{valid_min_temps[i]}℃', ha='center', va='top')
    
    plt.tight_layout()
    plt.savefig(f'{city_name}_weather_forecast.png')
    plt.close()
    print(f"{city_name}天气数据可视化完成")

# 保存为CSV文件
def save_to_csv(weather_list, city_name):
    if not weather_list:
        print("没有数据可保存")
        return
    
    df = pd.DataFrame(weather_list)
    filename = f'{city_name}_weather_data.csv'
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"数据已保存到{filename}")

# 主函数
def main():
    # 城市代码示例（北京）
    city_code = '101010100'
    city_name = '北京'
    
    print(f"开始获取{city_name}天气数据...")
    html = get_weather_data(city_code)
    
    if html:
        weather_list = parse_weather_data(html)
        weather_list = process_temperature(weather_list)
        
        print(f"成功获取{len(weather_list)}天的天气数据")
        
        # 保存数据
        save_to_csv(weather_list, city_name)
        
        # 可视化数据
        visualize_weather(weather_list, city_name)
    else:
        print("获取天气数据失败")

if __name__ == '__main__':
    main()
```

## 实际示例

### 多城市天气数据爬取与对比

```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import matplotlib.pyplot as plt
import json
from concurrent.futures import ThreadPoolExecutor

# 设置中文字体
plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

class WeatherCrawler:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        }
        # 城市代码字典
        self.city_codes = {
            '北京': '101010100',
            '上海': '101020100',
            '广州': '101280101',
            '深圳': '101280601',
            '杭州': '101210101',
            '成都': '101270101'
        }
        self.all_weather_data = {}
    
    def get_weather_data(self, city_name):
        """获取指定城市的天气数据"""
        city_code = self.city_codes.get(city_name)
        if not city_code:
            print(f"未找到{city_name}的城市代码")
            return None
        
        url = f'http://www.weather.com.cn/weather/{city_code}.shtml'
        
        try:
            # 添加随机延时，避免被反爬
            time.sleep(random.uniform(1, 3))
            
            response = requests.get(url, headers=self.headers, timeout=10)
            response.encoding = 'utf-8'  # 确保中文正常显示
            
            if response.status_code == 200:
                return response.text
            else:
                print(f"{city_name}请求失败: {response.status_code}")
                return None
        except Exception as e:
            print(f"{city_name}请求异常: {e}")
            return None
    
    def parse_weather_data(self, html, city_name):
        """解析天气数据"""
        if not html:
            return []
        
        soup = BeautifulSoup(html, 'html.parser')
        weather_list = []
        
        # 定位7天天气数据
        weather_divs = soup.select('div.c7d > ul.t.clearfix > li')
        
        for div in weather_divs:
            try:
                # 提取日期
                date = div.select_one('h1').text
                
                # 提取天气状况
                weather = div.select_one('p.wea').text
                
                # 提取温度范围
                temp_range = div.select_one('p.tem').text.strip()
                
                # 提取风向
                wind = div.select_one('p.win > i').text
                
                # 存储天气信息
                weather_info = {
                    'city': city_name,
                    'date': date,
                    'weather': weather,
                    'temp_range': temp_range,
                    'wind': wind
                }
                
                weather_list.append(weather_info)
            except Exception as e:
                print(f"{city_name}解析数据异常: {e}")
        
        return weather_list
    
    def process_temperature(self, weather_list):
        """处理温度数据"""
        for item in weather_list:
            temp_text = item['temp_range']
            # 分离最高温和最低温
            temps = temp_text.replace('℃', '').split('/')
            
            if len(temps) == 2:
                max_temp = temps[0].strip()
                min_temp = temps[1].strip()
            else:
                # 如果只有一个温度值
                max_temp = temp_text.replace('℃', '').strip()
                min_temp = max_temp
            
            # 转换为数字
            try:
                item['max_temp'] = int(max_temp)
            except:
                item['max_temp'] = None
                
            try:
                item['min_temp'] = int(min_temp)
            except:
                item['min_temp'] = None
        
        return weather_list
    
    def crawl_city_weather(self, city_name):
        """爬取单个城市的天气数据"""
        print(f"开始获取{city_name}天气数据...")
        html = self.get_weather_data(city_name)
        
        if html:
            weather_list = self.parse_weather_data(html, city_name)
            weather_list = self.process_temperature(weather_list)
            
            print(f"成功获取{city_name} {len(weather_list)}天的天气数据")
            return weather_list
        else:
            print(f"获取{city_name}天气数据失败")
            return []
    
    def crawl_all_cities(self):
        """爬取所有城市的天气数据"""
        # 使用线程池并行爬取
        with ThreadPoolExecutor(max_workers=3) as executor:
            # 提交所有任务
            future_to_city = {executor.submit(self.crawl_city_weather, city): city for city in self.city_codes.keys()}
            
            # 获取结果
            for future in future_to_city:
                city = future_to_city[future]
                try:
                    weather_list = future.result()
                    if weather_list:
                        self.all_weather_data[city] = weather_list
                except Exception as e:
                    print(f"{city}爬取失败: {e}")
        
        return self.all_weather_data
    
    def save_all_data(self):
        """保存所有城市的天气数据"""
        if not self.all_weather_data:
            print("没有数据可保存")
            return
        
        # 合并所有城市数据
        all_data = []
        for city, data in self.all_weather_data.items():
            all_data.extend(data)
        
        # 保存为CSV
        df = pd.DataFrame(all_data)
        df.to_csv('all_cities_weather.csv', index=False, encoding='utf-8-sig')
        print("所有城市天气数据已保存到all_cities_weather.csv")
        
        # 保存为JSON
        with open('all_cities_weather.json', 'w', encoding='utf-8') as f:
            json.dump(self.all_weather_data, f, ensure_ascii=False, indent=4)
        print("所有城市天气数据已保存到all_cities_weather.json")
    
    def visualize_temperature_comparison(self):
        """可视化多城市温度对比"""
        if not self.all_weather_data:
            print("没有数据可视化")
            return
        
        # 准备数据
        plt.figure(figsize=(14, 8))
        
        # 获取所有日期
        all_dates = set()
        for city_data in self.all_weather_data.values():
            for item in city_data:
                all_dates.add(item['date'])
        
        all_dates = sorted(list(all_dates))[:7]  # 最多取7天
        
        # 为每个城市绘制最高温度曲线
        for city, data in self.all_weather_data.items():
            # 构建日期-温度映射
            date_to_temp = {item['date']: item.get('max_temp') for item in data if item.get('max_temp') is not None}
            
            # 提取对应日期的温度
            temps = [date_to_temp.get(date) for date in all_dates if date in date_to_temp]
            valid_dates = [date for date in all_dates if date in date_to_temp]
            
            if temps and valid_dates:
                plt.plot(valid_dates, temps, 'o-', label=f'{city}最高温')
        
        plt.title('多城市未来天气最高温对比')
        plt.xlabel('日期')
        plt.ylabel('温度(℃)')
        plt.legend()
        plt.grid(True)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('cities_temperature_comparison.png')
        plt.close()
        print("多城市温度对比可视化完成")
    
    def visualize_weather_distribution(self):
        """可视化天气状况分布"""
        if not self.all_weather_data:
            print("没有数据可视化")
            return
        
        # 统计各城市天气状况
        city_weather_counts = {}
        
        for city, data in self.all_weather_data.items():
            # 统计天气状况
            weather_counts = {}
            for item in data:
                weather = item['weather']
                weather_counts[weather] = weather_counts.get(weather, 0) + 1
            
            city_weather_counts[city] = weather_counts
        
        # 绘制饼图
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        for i, (city, weather_counts) in enumerate(city_weather_counts.items()):
            if i < len(axes):
                labels = list(weather_counts.keys())
                sizes = list(weather_counts.values())
                
                axes[i].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
                axes[i].set_title(f'{city}天气状况分布')
        
        plt.tight_layout()
        plt.savefig('cities_weather_distribution.png')
        plt.close()
        print("天气状况分布可视化完成")

# 主函数
def main():
    crawler = WeatherCrawler()
    crawler.crawl_all_cities()
    crawler.save_all_data()
    crawler.visualize_temperature_comparison()
    crawler.visualize_weather_distribution()

if __name__ == '__main__':
    main()
```

## 思考题

1. 如何优化多城市天气数据的爬取效率？多线程和异步爬取各有什么优缺点？
2. 天气网站的数据可能会动态更新，如何设计爬虫以适应这种变化？
3. 对于不同城市的天气数据，如何设计更合理的数据存储结构？
4. 如何扩展爬虫功能，使其能够爬取更多维度的天气信息，如空气质量、湿度等？
5. 在数据可视化方面，还有哪些图表类型可以更好地展示天气数据的特点？

## 小结

- **<font color="red">天气数据爬取是爬虫技术在实际生活中的典型应用</font>**
- **<font color="blue">多城市数据的并行爬取可以有效提高爬虫效率</font>**
- **<font color="green">数据清洗和结构化处理对于后续分析至关重要</font>**
- **<font color="purple">可视化技术能够直观展示天气数据的特点和趋势</font>**
- **<font color="orange">完整的爬虫项目需要考虑异常处理、数据存储和展示等多个方面</font>**

## 总结

本节课通过天气数据爬取的实战案例，展示了一个完整爬虫项目的开发流程。从单城市天气数据爬取到多城市数据的并行获取与对比分析，我们详细讲解了数据采集、处理、存储和可视化的各个环节。通过这个实战案例，学习者可以将前面学习的各种爬虫技术综合应用，掌握构建实用爬虫项目的方法。在实际开发中，还需要根据具体需求和目标网站的特点，灵活运用各种技术，不断优化爬虫的性能和稳定性。