【第 5 章 - 提示词优化与迭代调试】
5.4 给提示词瘦身：把一本字典塞进一个胶囊

你可能会问：
“现在的模型动不动就支持 128k 甚至 1M 的上下文，我还需要在乎那几个字的长度吗？”
答案是：要。而且非常要。
原因有两个：
第一，虽然Token越来越便宜，但在高频 API 调用或者构建包含大量知识库的 RAG（检索增强生成）系统时，每一个浪费的 Token 都在烧钱。
第二，也是更重要的一点：**信息密度决定了 AI 的注意力密度**。
你给一篇 1 万字的废话文章，AI 可能会漏掉其中的关键指令。
你给一段 100 字的精炼指令，AI 的执行效率会达到巅峰。
Prompt Engineering 的最高境界，不是写得长，而是写得短，但信息量极大。
这就好比发电报，按字收费，你必须学会“惜字如金”。

一、 压缩定律一：删掉那些客套话
AI 不需要礼貌。
你不需要说：“亲爱的 AI 助手，能不能麻烦你帮我做一件事……”
你也不需要说：“非常感谢你的帮助，你的回答太棒了。”
在指令层面上，这些都是噪音。
**V1（啰嗦版）：**
“请你能不能帮我把下面这段关于环保的文章总结一下？我希望你能提取出最重要的三个观点，不要太长，尽量简练一点。”（48 字）
**V2（压缩版）：**
“任务：总结文本当中三个核心观点。要求：简练。”（18 字）
字数减少了 62%，但指令的清晰度反而提升了。
记住，对 AI 来说：**动词 + 名词 = 最强指令**。

二、 压缩定律二：符号化与伪代码
大模型在训练时看过海量的代码。
这意味着它对符号逻辑的理解能力，远超自然语言。
我们可以用符号来代替冗长的连接词。
**常用符号对照表：**
-   `->` 代替 “意味着”、“导致”、“下一步是”
-   `w/` 代替 "with"（伴随）
-   `w/o` 代替 "without"（没有）
-   `xxx | xxx | xxx` 代替 “第一点是xxx，第二点是xxx...”
-   `#` 代替 “标题”、“主题”

**实战案例：**
**V1（自然语言）：**
“请分析这家公司的优势和劣势。如果优势大于劣势，就建议买入；如果劣势大于优势，就建议卖出。”
**V2（伪代码）：**
```
Analyze(Company):
  List(Pros, Cons)
  If (Pros > Cons) -> Recommend: Buy
  Else -> Recommend: Sell
```
看起来是不是很像程序员写的？
没错，AI 看到这种格式，会立刻切换到“逻辑执行模式”，大大降低理解偏差。

三、 压缩定律三：定义变量与模块复用
这是从编程里学来的最高级技巧。
如果你需要反复让 AI 执行同一个规则，不要每次都把规则写一遍。
你可以先定义一个“变量”或“函数”。

**Step 1：定义规则**
“定义规则 $CleanText：所有的输出都要去除口语词，使用书面语，并按 Markdown 列表输出。”

**Step 2：调用规则**
以后你只需要说：
“处理这段文本，应用 $CleanText。”
AI 就会自动调取上下文里的那个规则。
这在进行长对话或者构建 AI 助手（Agent）时，能节省海量的 Token。

四、 极限挑战：把 Prompt 压缩到极致
让我们来做一个极其实用的练习。
这就好比你想把一本《新华字典》的内容塞进一个小胶囊里。
**任务**：让 AI 扮演一个专业的英语雅思私教。
**常规写法（200 字）**：
“你是一个雅思老师，你要帮我改作文。你要先看我的语法有没有错，如果有错就改过来。然后你要看我的词汇高不高级，如果不高级就换个高级词。最后你要给我打分……”
**压缩写法（Json 格式）：**
```json
{
  "Role": "IELTS_Tutor",
  "Task": "Correct & Upgrade",
  "Steps": [ "Fix Grammar", "Enhance Vocab", "Score (0-9)" ],
  "Output": "Table"
}
```
把这个扔给 AI，它完全看得懂，而且执行得丝滑无比。

五、 本节小结
提示词压缩，不仅是为了省钱，更是为了**提纯思维**。
当你逼迫自己把 100 个字压缩成 10 个字时，你必须想清楚：**我到底想要什么？**
去掉枝蔓，留下主干。
这不仅是写 Prompt 的心法，也是高效沟通的心法。

写到这里，我们的“闭环优化”部分就结束了。
现在，你已经学会了怎么写（第 2-4 章），也学会了怎么改（第 5 章）。
你手里的武器已经打磨得足够锋利了。
但是，江湖上门派林立。
同样一套剑法，用在不同的人身上，效果可能不同。
下一章，我们将进入**“大模型横评”**。
ChatGPT、Claude、文心一言、Kimi……这些性格各异的模型，到底谁才是你的“本命”？
我会手把手教你如何“看人下菜碟”。
