

第5.1章 吐槽大会：为啥 AI 总在胡说八道

很多时候，我们满怀期待地敲下回车，结果屏幕上蹦出来的东西让人只想砸键盘。
这玩意儿也能叫人工智能？简直是人工智障。
先别急着发火。在医学上，要想治病，先得确诊。
如果你的 AI“病了”，我们得先看看它得的是什么病，才能对症下药。
这一节，我们不讲大道理，先开个“吐槽大会”，把 AI 最常见的三种“病症”拎出来晒一晒。
只有看懂了这些病，你才能在下一节学会怎么治它。

一、 一号病历：一本正经的胡说八道综合征
这是最让人生气的一种病。
你问它：“鲁迅为什么要暴打周树人？”
它不假思索地回答：“因为周树人欠了鲁迅的钱，两人在咸亨酒店发生了激烈的肢体冲突，导致周树人受伤住院。”
听听，多有逻辑，多有细节，甚至地点人物都对上了。
唯一的缺点是：全是瞎编的。
在专业术语里，这叫“幻觉”（Hallucination）。
当你把 AI 当作搜索引擎来用，或者问它一些它知识库里没有的冷门知识时，这种病就会发作。
它太想讨好你了。它依然像个怕老师提问的小学生，因为不知道答案，又不敢交白卷，于是硬着头皮编了一个看似完美的谎话。
这种病的特点是：语气极其自信，内容极其离谱。
如果你在写财报分析或者医疗咨询时遇到了这种病，那简直是灾难。

二、 二号病历：像老太太裹脚布一样的车轱辘话
你让它写个 200 字的商品文案。
它洋洋洒洒给你写了 800 字。
仔细一读，全是这种废话：
“这款产品不仅外观精美，而且功能强大。它的外观设计非常精美，让人一见倾心。同时，它的功能也十分强大，能够满足您的各种需求。总而言之，这是一款集美观与实用于一身的好产品……”
你看，它把一句话翻来覆去说了四遍。
这就好比凑字数写论文的大学生，为了撑满篇幅，把“因为”改成“由于”，把“但是”改成“然而”，其实核心信息量为零。
这种病通常是因为你没有给它设定清晰的“信息密度”要求，或者你的反向提示词（还记得 3.5 节的红线吗？）没设好。
它觉得你需要“丰富”的内容，于是就开始注水。

三、 三号病历：完全听不懂人话的逻辑黑洞
你跟它说：“我要一个蓝色的 Logo，不要有圆圈。”
结果它给你画了一个蓝色的圆圈。
你气得想笑：“你是故意的吧？”
这其实是因为大模型对“否定词”的理解有时会短路。
在它的神经网络里，“圆圈”这个特征被激活了，而“不要”这个逻辑词的权重太低，被淹没在了“蓝色”和“圆圈”的强信号里。
或者，你的指令太复杂了，像一团乱麻。
“帮我写个故事，男主是警察但也是小偷，故事要发生在古代但要有科幻元素，结局要悲剧但也要有希望……”
AI 听完直接死机：大哥，你到底要啥？
这就好比你去理发店跟 Tony 老师说：“我要剪一个看起来很长但其实很短，很低调但又很非主流的发型。”
Tony 老师手里的剪刀也会抖三抖。

四、 既然病因找到了，那是谁的锅？
当 AI 表现不好时，99% 的情况下，锅在你自己身上。
别急着反驳，我们来做一个“归因分析”。
通常由三个要素决定了 AI 的回答质量：

1. 输入的信息质量（Garbage In）
如果你给它的原材料就是烂的，它做不出满汉全席。
你扔给它一段乱七八糟、没有标点、逻辑不通的语音转文字记录，让它整理会议纪要。
它光是猜你在说啥就耗尽了所有算力，哪里还有空帮你提炼重点？

2. 上下文的缺失（No Context）
你直接问：“这件衣服多少钱？”
AI 一脸懵逼：“哪件？”
你以为你们在聊淘宝，而在 AI 的视角里，这是你们的第一句话。
很多时候，我们默认 AI 知道我们的背景、身份、喜好，但其实它只是一个刚刚被初始化的程序。
你不告诉它“我是个穷学生，预算只有 50 块”，它就会给你推荐 5000 块的大衣。

3. 模型的先天不足（Model Limitation）
这属于不可抗力。
如果你非要用轻量级的手机端模型去解奥数题，那它确实做不到。
或者你非要用 ChatGPT 3.5 去问 2024 年才发生的新闻，它也只能两手一摊。
这时候，你需要换个更聪明的脑子（比如换用 GPT-4），或者给它外接一个大脑（比如开启联网搜索插件，这在第 7 章会讲）。

五、 怎么判断 AI 的回答及不及格？
在开始“治疗”之前，我们需要一把尺子。
我们要建立一套评估体系，不能只凭感觉说“好”或“不好”。
我建议你用“3C 标准”来给 AI 打分：

标准一：Correctness（准确性）
它说的事实对不对？数据准不准？代码能不能跑通？
这是底线。特别是涉及客观事实的问题，错一个字都不行。
哪怕它文笔再好，如果把“李白”说成是“宋朝人”，那就是零分。

标准二：Conciseness（简洁性）
它有没有废话？有没有车轱辘话？
在信息爆炸的时代，能用 10 个字说清楚的，绝不用 20 个字。
好的 AI 回答应该是干脆利落的，像某种精密的仪器，每一个字都有它的作用。

标准三：Customization（定制性）
它有没有听懂你的“弦外之音”？
如果你让他写周报，它写得像小学生作文，那就是定制性差。
如果你让他写情书，它写得像政府公文，那也是定制性差。
一个好的回答，应该让你感觉“这正是我想要的那个味儿”。

六、 课后小作业
翻翻你最近和 AI 的聊天记录。
找出一个让你觉得“这什么玩意儿”的失败案例。
对照上面的“3C 标准”，给它打个分。
也就是问问自己：它是事实错了？还是废话太多？还是风格不对？
只要你能准确地说出它哪里不好，下一节这一章的“手术刀”——迭代优化法，就能帮你把它治好。

准备好了吗？
我们要穿上白大褂，进入手术室了。
下一节，怎么通过“多轮对话”，把一个智障调教成天才。


第5.2章 别想一次就成：好咒语都是“磨”出来的

你有没有过这种幻想：
我也想像电影里的哈利波特一样，挥一挥魔杖，念一句咒语，全世界就按照我的意愿运转。
于是你期待写出一个完美的 Prompt，按下回车，AI 就给你一个完美的结果。
醒醒吧，那不叫提示词工程，那叫抽奖。
在真实的开发和创作中，从来没有“一次成型”的代码，也没有“一遍过”的提示词。
所有的高手都是“缝缝补补”过来的。
这一节，我要教你一项核心技能——“迭代”。
简单说，就是怎么和 AI 吵架，直到它服气为止。

一、 为什么需要迭代？
我们来复盘一下人机沟通的本质。
你脑子里有一个 100% 完美的想法。
当你把它变成语言时，因为表达能力的限制，可能只剩下了 80%。
当你把这些语言输入给 AI 时，因为它对上下文理解的缺失，可能只接收到了 60%。
最后它输出结果时，因为随机性和模型能力的限制，可能只呈现出了 40%。
从 100% 到 40%，中间全是信息的损耗。
为了弥补这些损耗，我们不能只说一次。我们需要通过多轮对话，不断地把偏差拉回来。
这就是为什么我说：好的结果不是“命令”出来的，而是“聊”出来的。

二、 第一招：切香肠式追问法
很多时候，AI 给你一个笼统的回答，是因为你不敢追问。
你问：“如何提高工作效率？”
AI 回：“制定计划、保持专注、学会休息。”
这回答有错吗？没错。有用吗？完全没用。
这时候，千万别关掉对话框。你要像切香肠一样，一层一层切下去。
第一轮追问（聚焦）：
“你提到了制定计划。但我有拖延症，总是计划赶不上变化。针对拖延症患者，有什么具体的计划制定方法？”
AI 会给出“番茄工作法”或“SMART 原则”。
第二轮追问（落地）：
“番茄工作法我试过，但我一休息 5 分钟就很难再回到工作状态。这种情况该怎么办？”
AI 会给出更具体的建议，比如“微习惯”或者“环境隔离”。
第三轮追问（场景化）：
“我现在就在办公室，周围很吵，我又不能戴耳机。这种环境下怎么做环境隔离？”
看到了吗？通过三次追问，你把一句正确的废话，逼成了一个可执行的落地方案。
AI 就像个牙膏，你不挤，它不流。

三、 第二招：找茬式纠错法
当 AI 犯错时（比如我们在 5.1 节里提到的那些病），很多人的反应是重新开一个对话窗口，把 Prompt 改一下再发一遍。
太浪费了！
你应该直接在当前的对话里指着它的鼻子骂（当然要礼貌一点）。
这种方法叫“负反馈修正”。
比如你要它写代码，它报错了。
错误做法：把报错关了，自己去查谷歌。
正确做法：直接把报错信息复制给它，并说：“你给的代码报错了，错误信息如下。请分析原因并修改代码。”
比如你要它写小说，它写得太平淡。
错误做法：叹口气，自己改。
正确做法：告诉它：“这一段写得太像说明书了。我需要更多的心理描写。请重写这一段，重点描写主角听到噩耗时手抖的细节。”
记住，AI 是没有自尊心的。你指出错误越具体，它修正得越快。它不会觉得你难伺候，它只会觉得你的指令很清晰。

四、 第三招：左右互搏法
这招比较高级，适用于你也不知道自己想要什么的时候。
你可以让 AI 自己跟自己打架。
场景：你想给公司起个名字，但没灵感。
第一步（发散）：
“请帮我想 10 个科技公司的名字，风格要现代、简洁。”
AI 给了一堆：智联、创想、未来科技……（都很俗）。
第二步（批判）：
“这些名字太普通了，在商标局肯定注册不下来。请你作为一个苛刻的品牌顾问，批评一下这 10 个名字的缺点。”
AI 会自我批评：“‘智联’太大众化，缺乏辨识度……”
第三步（迭代）：
“很好。现在请根据你的批评意见，重新再想 10 个名字。要求避开刚才提到的所有缺点，哪怕生僻一点也可以。”
这次，它可能会给出：“星野、极昼、量极……”
通过让 AI 自己否定自己，你可以逼迫它跳出概率最高的那个平庸区域，去探索更深层的创意。

五、 完整的迭代实战演示
让我们来看一个真实的“灾难现场”是如何被救回来的。
目标：写一个关于“失眠”的短视频脚本。

第 1 版 Prompt（小白版）：
“帮我写个短视频脚本，主题是失眠。”
AI 产出：
画面：一个人躺在床上翻来覆去。
旁白：你失眠了吗？失眠很痛苦。我们要早睡早起……
（评价：毫无亮点，刷到必划走。）

第 2 版 Prompt（加入红线）：
“这个太无聊了。我要那种能引起共鸣的。不要说教。要走心。”
AI 产出：
画面：深夜的窗外，月光洒在床上。
旁白：夜深了，整个城市都睡了，只有你还醒着。孤独像潮水一样……
（评价：好了一点，但还是像网抑云语录。）

第 3 版 Prompt（具体化 + 风格迁移）：
“还是太矫情。我要那种王家卫风格的。讲一个失眠的人在便利店买东西的故事。要有独白。”
AI 产出：
画面：凌晨 3 点，便利店冷白的灯光。主角拿了一罐过期的凤梨罐头。
旁白：我们在凌晨三点相遇。我在想，如果记忆也是一个罐头，我希望它永远不会过期……但是失眠会。
（评价：味道对了！这就是我们要的。）

六、 本节小结
好 Prompt 的标准只有一个：能得到好结果。
至于它是第一次生成的，还是第十次改出来的，根本不重要。
别怕麻烦，别怕啰嗦。
把 AI 当成你的实习生，多给它一点耐心，多给它一点反馈。
你会发现，它成长的速度，比你想象的要快得多。

下一节，我们将借用互联网产品经理的一个概念——“A/B 测试”。
当你纠结是用“请分析”还是“请评价”时，为什么不让数据来告诉你答案呢？


第5.3章 让数据说话：像产品经理一样做“AB测试”

在互联网公司，产品经理在决定按钮颜色是“红色”还是“绿色”时，从来不拍脑袋。
他们会把一半用户分到红色组，一半分到绿色组，然后看哪一组的点击率高。
这就是著名的 A/B 测试（A/B Testing）。
在提示词工程中，我们也面临同样的困惑：
“写得简洁一点”和“写得精炼一点”，这两个指令对 AI 来说有区别吗？
“请一步步思考”和“请按逻辑顺序推理”，哪个效果更好？
答案是：谁也不知道。因为大模型是个黑盒。
唯一能告诉你真相的，只有测试。
这一节，我们要把这种科学的实验精神引入到 Prompt 编写中，找出那些能触发 AI“超神模式”的黄金关键词。

一、 哪怕只改一个词，结果都有大不同
别以为 AI 懂同义词。
在它的神经网络里，每个词对应的向量坐标都是不一样的。
我曾经做过一个实验，让 AI 给一篇小说写“评语”。
测试组 A：请对这篇小说进行“评价”。
测试组 B：请对这篇小说进行“鉴赏”。
结果大相径庭。
A 组（评价）：AI 变得像个语文老师，开始挑刺，说结构不够严谨，用词不够华丽，甚至指出了错别字。
B 组（鉴赏）：AI 瞬间变成了文学批评家，开始分析隐喻、象征意义，甚至引用了莎士比亚来升华立意。
为什么？
因为在语料库里，“评价”往往和作业、考试、商品挂钩；而“鉴赏”往往和艺术品、名著挂钩。
一个词的改变，直接切换了 AI 的“人设”。
这就是 A/B 测试的意义：寻找那些能精准激活特定神经网络区域的“开关”。

二、 实战一：语气词的 A/B 测试
场景：你想让 AI 写个搞笑的段子。
你可能会纠结用什么词来形容“搞笑”。
让我们来设几组对照：
Version A：Write a "funny" story.（好笑的）
Version B：Write a "humorous" story.（幽默的）
Version C：Write a "witty" story.（诙谐/机智的）
Version D：Write a "hilarious" story.（爆笑的）

测试结果：
A 组（Funny）：AI 给出了那种最普通的笑话，比如“为什么数学书很伤心？因为它有太多问题”。适合小学生。
B 组（Humorous）：AI 写出了带点英式冷幽默的故事，比较含蓄。
C 组（Witty）：AI 写出了充满机智对白和反转的故事，类似伍迪·艾伦的风格。
D 组（Hilarious）：AI 开始用力过猛，用了很多夸张的形容词和感叹号，像闹剧。

结论：如果你想要高级的幽默，请用 "Witty"；如果你想要简单的快乐，请用 "Funny"。
不测不知道，一测吓一跳。

三、 实战二：结构顺序的 A/B 测试
场景：你想写一篇长文。
你也知道要拆解任务（见 3.4 节），但怎么拆效果最好？
Version A（先大纲后正文）：
指令 1：写大纲。
指令 2：根据大纲写正文。
Version B（直接给大纲写正文）：
指令：这里有一份大纲[粘贴大纲]，请根据它写正文。
Version C（分段写）：
指令 1：写第一章。
指令 2：写第二章。

测试结果：
通常情况下，Version C 的字数最多，细节最丰富。
Version A 的逻辑连贯性最好，但字数可能偏少。
Version B 的效果最差，因为 AI 的注意力被那一长串大纲分散了，容易顾此失彼。
所以，对于超长文本，分段生成（Version C）永远是王道。

四、 实战三：不同模型的 A/B 测试
同一个 Prompt，在 ChatGPT 4.0 上表现完美，扔给 Claude 3 可能就哑火了。
各家模型的“脾气”是不一样的（第 6 章我们会详细讲）。
比如写代码：
GPT-4：喜欢解释原理，代码稳健，但废话多。
Claude 3：代码简洁，一次性通过率高，但不爱写注释。
如果你是新手，GPT-4 更好；如果你是老手，Claude 3 更爽。
这也是一种 A/B 测试。你需要建立自己的“模型适应性清单”。

五、 怎么做测试才科学？（控制变量法）
做 A/B 测试最忌讳的是“乱改”。
你想优化一个 Prompt，于是你把“Role”改了，把“Task”改了，还加了一句“请深呼吸”。
结果效果变好了。
请问：是因为哪一个改动变好的？
你不知道。下次你就没法复制这个成功。
所以，请遵循“单一变量原则”：
每次只改一个地方。
1. 第 1 轮：只改动 Role（从“作家”改为“编剧”），看看效果。
2. 第 2 轮：只改动 Style（从“严肃”改为“活泼”），看看效果。
3. 第 3 轮：只改动 Example（换几个例子），看看效果。
这确实很麻烦，很费时间。
但所有顶级的 Prompt（比如那些在网上卖几百块钱的），都是这么一轮一轮“磨”出来的。

六、 课后小作业
哪怕你不想做那么复杂的科学实验，至少要在心里保留这种意识。
下次当你觉得 AI 写得不够好时，试着换一个同义词。
把“写一篇报道”改成“撰写一篇深度报道”。
把“总结一下”改成“提炼核心洞察”。
把“解释给我听”改成“像教 5 岁孩子一样教我”。
哪怕微小的改动，都可能引发蝴蝶效应。
试一试，看看你的 AI 会给你什么惊喜。

下一节，我们将讨论一个硬核话题——“提示词压缩”。
如果上下文窗口不够用了怎么办？
如果我们想把一个复杂的指令集塞进有限的 Token 里，有没有办法给它“瘦身”？


第5.4章 给提示词瘦身：把一本字典塞进一个胶囊

你可能会问：
“现在的模型动不动就支持 128k 甚至 1M 的上下文，我还需要在乎那几个字的长度吗？”
答案是：要。而且非常要。
原因有两个：
第一，虽然Token越来越便宜，但在高频 API 调用或者构建包含大量知识库的 RAG（检索增强生成）系统时，每一个浪费的 Token 都在烧钱。
第二，也是更重要的一点：信息密度决定了 AI 的注意力密度。
你给一篇 1 万字的废话文章，AI 可能会漏掉其中的关键指令。
你给一段 100 字的精炼指令，AI 的执行效率会达到巅峰。
Prompt Engineering 的最高境界，不是写得长，而是写得短，但信息量极大。
这就好比发电报，按字收费，你必须学会“惜字如金”。

一、 压缩定律一：删掉那些客套话
AI 不需要礼貌。
你不需要说：“亲爱的 AI 助手，能不能麻烦你帮我做一件事……”
你也不需要说：“非常感谢你的帮助，你的回答太棒了。”
在指令层面上，这些都是噪音。
V1（啰嗦版）：
“请你能不能帮我把下面这段关于环保的文章总结一下？我希望你能提取出最重要的三个观点，不要太长，尽量简练一点。”（48 字）
V2（压缩版）：
“任务：总结文本当中三个核心观点。要求：简练。”（18 字）
字数减少了 62%，但指令的清晰度反而提升了。
记住，对 AI 来说：动词 + 名词 = 最强指令。

二、 压缩定律二：符号化与伪代码
大模型在训练时看过海量的代码。
这意味着它对符号逻辑的理解能力，远超自然语言。
我们可以用符号来代替冗长的连接词。
常用符号对照表：
-   `->` 代替 “意味着”、“导致”、“下一步是”
-   `w/` 代替 "with"（伴随）
-   `w/o` 代替 "without"（没有）
-   `xxx | xxx | xxx` 代替 “第一点是xxx，第二点是xxx...”
-   `` 代替 “标题”、“主题”

实战案例：
V1（自然语言）：
“请分析这家公司的优势和劣势。如果优势大于劣势，就建议买入；如果劣势大于优势，就建议卖出。”
V2（伪代码）：
```
Analyze(Company):
  List(Pros, Cons)
  If (Pros > Cons) -> Recommend: Buy
  Else -> Recommend: Sell
```
看起来是不是很像程序员写的？
没错，AI 看到这种格式，会立刻切换到“逻辑执行模式”，大大降低理解偏差。

三、 压缩定律三：定义变量与模块复用
这是从编程里学来的最高级技巧。
如果你需要反复让 AI 执行同一个规则，不要每次都把规则写一遍。
你可以先定义一个“变量”或“函数”。

Step 1：定义规则
“定义规则 $CleanText：所有的输出都要去除口语词，使用书面语，并按 Markdown 列表输出。”

Step 2：调用规则
以后你只需要说：
“处理这段文本，应用 $CleanText。”
AI 就会自动调取上下文里的那个规则。
这在进行长对话或者构建 AI 助手（Agent）时，能节省海量的 Token。

四、 极限挑战：把 Prompt 压缩到极致
让我们来做一个极其实用的练习。
这就好比你想把一本《新华字典》的内容塞进一个小胶囊里。
任务：让 AI 扮演一个专业的英语雅思私教。
常规写法（200 字）：
“你是一个雅思老师，你要帮我改作文。你要先看我的语法有没有错，如果有错就改过来。然后你要看我的词汇高不高级，如果不高级就换个高级词。最后你要给我打分……”
压缩写法（Json 格式）：
```json
{
  "Role": "IELTS_Tutor",
  "Task": "Correct & Upgrade",
  "Steps": [ "Fix Grammar", "Enhance Vocab", "Score (0-9)" ],
  "Output": "Table"
}
```
把这个扔给 AI，它完全看得懂，而且执行得丝滑无比。

五、 本节小结
提示词压缩，不仅是为了省钱，更是为了提纯思维。
当你逼迫自己把 100 个字压缩成 10 个字时，你必须想清楚：我到底想要什么？
去掉枝蔓，留下主干。
这不仅是写 Prompt 的心法，也是高效沟通的心法。

写到这里，我们的“闭环优化”部分就结束了。
现在，你已经学会了怎么写（第 2-4 章），也学会了怎么改（第 5 章）。
你手里的武器已经打磨得足够锋利了。
但是，江湖上门派林立。
同样一套剑法，用在不同的人身上，效果可能不同。
下一章，我们将进入“大模型横评”。
ChatGPT、Claude、文心一言、Kimi……这些性格各异的模型，到底谁才是你的“本命”？
我会手把手教你如何“看人下菜碟”。


第6.1章 ChatGPT：这个全能学霸有点话痨

如果把 AI 模型比作班级里的同学，那 ChatGPT 就是那个永远坐第一排、什么都会、老师最喜欢的三好学生。
它是目前全球用户量最大、知名度最高的大语言模型，没有之一。
从 2022 年 11 月横空出世到现在，ChatGPT 已经成了"AI"的代名词。
但是，就像每个学霸都有自己的脾气一样，ChatGPT 也有它独特的"人设"。
如果你不了解它的性格，就很容易踩坑。
这一节，我们来聊聊怎么和这位"全能选手"打交道。

一、 ChatGPT 的性格画像
想象一下，你身边有这样一个朋友：
他知识渊博，上知天文下知地理，你问他任何问题他都能侃侃而谈。
但他有个毛病：太爱解释了。
你问他"北京今天天气怎么样"，他能给你讲半小时关于季风气候的形成原理。
你让他写个 100 字的文案，他非要给你写 500 字，还附带三个版本供你选择。
这就是 ChatGPT 的典型特征：热情、啰嗦、求全责备。
它总是想把所有可能的答案都告诉你，生怕漏掉什么重要信息。
这在某些场景下是优点（比如学习新知识），但在某些场景下就是灾难（比如你赶时间要个结论）。

二、 ChatGPT 最擅长的三件事
虽然它号称"全能"，但术业有专攻。
以下三个场景，ChatGPT 的表现堪称完美：

场景一：知识问答与概念解释
当你想学习一个新概念，或者需要快速了解某个领域的基础知识时，ChatGPT 是最好的老师。
它会用最通俗易懂的语言，结合大量的类比和例子，把复杂的东西讲清楚。
比如你问："什么是区块链？"
它不会直接甩给你一堆技术术语，而是会说："想象一下，你和朋友们一起记账……"
这种"费曼式教学"的能力，是 ChatGPT 的看家本领。

场景二：头脑风暴与创意发散
当你脑子卡壳，需要灵感时，ChatGPT 就像一个永不疲倦的创意伙伴。
你说："帮我想 10 个咖啡店的名字。"
它会瞬间给你从文艺到沙雕的全套方案。
而且它不会像人类一样说"我想不出来了"，你让它想 100 个，它真能给你想 100 个。
虽然质量参差不齐，但总有几个能让你眼前一亮。

场景三：文本润色与改写
如果你写了一段话，但总觉得不够优雅，或者想换个风格，ChatGPT 是最好的"文字化妆师"。
它可以把你的大白话改成商务邮件，也可以把你的论文改成小学生作文。
而且它对"语气"的把控非常精准。
你只需要告诉它"要更正式"或者"要更幽默"，它就能立刻调整。

三、 ChatGPT 的三大软肋
没有完美的模型，ChatGPT 也有它的阿喀琉斯之踵。

软肋一：时效性差（知识截止日期）
GPT-4 的知识库更新到 2023 年 10 月（具体日期会随版本更新）。
如果你问它 2024 年的新闻，或者最新的科技动态，它只能说"我不知道"。
虽然现在有联网插件可以弥补，但默认状态下，它就是个"活在过去"的老古董。
所以，千万别拿它当搜索引擎用。

软肋二：数学计算容易翻车
虽然 GPT-4 比之前的版本强多了，但它本质上还是个"语言模型"，不是"计算器"。
你问它"123456 乘以 789"，它可能会算错。
你问它复杂的微积分题，它可能会在推导过程中跳步。
如果你需要精确计算，请用 Code Interpreter（代码解释器）插件，让它写 Python 代码来算。

软肋三：容易被"带偏"
ChatGPT 有时候太"听话"了。
如果你在提问时暗示了某个错误的前提，它可能会顺着你的错误继续编。
比如你问："鲁迅为什么要打周树人？"
它可能不会纠正你"鲁迅就是周树人"，而是开始编故事。
所以，在使用时要保持批判性思维，别全信。

四、 给 ChatGPT 写 Prompt 的三个小技巧
基于它的性格特点，我总结了三条"驯服"它的心法：

技巧一：用"简洁"作为红线
在你的 Prompt 末尾加上这句话：
"请用最简洁的语言回答，不要超过 100 字。"
或者更狠一点：
"如果你的回答超过 3 句话，我就扣你工资。"（开玩笑，但真的有效）
这能有效遏制它的"话痨"倾向。

技巧二：让它"分步思考"
对于复杂的逻辑推理或者数学题，一定要加上"Let's think step by step"。
这会激活它的 CoT（思维链）模式，大幅提升准确率。
别嫌麻烦，这 5 个字能让正确率从 40% 提升到 80%。

技巧三：用"角色扮演"锁定风格
如果你想要特定风格的输出，别说"写得专业一点"。
直接告诉它："你是《纽约时报》的资深记者。"
或者："你是一个只会用 Emoji 说话的 00 后。"
角色设定越具体，输出越精准。

五、 本节小结
ChatGPT 就像一个热情过头的助教。
它什么都懂，但你得学会"管"它。
给它明确的边界，告诉它什么该说、什么不该说，它就能成为你最得力的助手。
记住：它不是神，它只是一个非常聪明的工具。
用好它，你能事半功倍；用不好它，你会被它的废话淹没。

下一节，我们将认识另一位选手——Claude。
如果说 ChatGPT 是热情的学霸，那 Claude 就是温柔的文艺青年。
它有着完全不同的气质，适合完全不同的场景。


第6.2章 Claude：温柔的长文本杀手

如果 ChatGPT 是那个热情洋溢、恨不得把所有知识都塞给你的学霸，那 Claude 就是坐在图书馆角落、戴着眼镜、安静看书的文艺青年。
它不会主动跟你搭话，但一旦你找它聊天，你会发现它的回答总是那么温柔、体贴、滴水不漏。
Claude 是由 Anthropic 公司开发的大语言模型，这家公司的创始团队来自 OpenAI（没错，就是做 ChatGPT 的那家）。
他们出走后，带着"让 AI 更安全、更可控"的理念，造出了这个性格完全不同的模型。
这一节，我们来聊聊这位"温柔杀手"的独特魅力。

一、 Claude 的性格画像
想象一下，你有这样一个朋友：
他说话永远不会咄咄逼人，哪怕你问了一个很蠢的问题，他也会温和地引导你。
他从来不会打断你，会耐心听你把话说完，然后给出深思熟虑的回答。
他写的文章逻辑严密、结构清晰，从来不会跑题或者车轱辘话。
这就是 Claude 的典型特征：温和、严谨、高效。
如果说 ChatGPT 是个话痨，那 Claude 就是个惜字如金的高手。
它不会给你一堆废话，它只给你最核心的答案。

二、 Claude 最擅长的三件事
虽然 Claude 相对低调，但在某些领域，它的表现甚至超过了 ChatGPT。

场景一：超长文本处理
这是 Claude 的绝活。
Claude 3 系列支持高达 200k tokens 的上下文窗口（相当于一本 15 万字的小说）。
而且它不像某些模型，窗口虽大但"记性"不好，经常前面说的话后面就忘了。
Claude 对长文本的理解和记忆能力极强。
你可以把一整本合同扔给它，让它找出所有的风险条款，它能精准定位。
你可以把一整篇论文扔给它，让它写综述，它能抓住每一个细节。
这种能力，在处理法律文书、学术论文、长篇小说时，简直是神器。

场景二：代码生成与调试
虽然 ChatGPT 也能写代码，但 Claude 在代码质量上往往更胜一筹。
它写出来的代码更简洁、更符合最佳实践，而且很少有低级错误。
更重要的是，它对代码的"审美"很好。
你让它重构一段屎山代码，它不会只是改改变量名，而是会从架构层面给你优化。
很多程序员反馈，Claude 写的代码"一次通过率"比 GPT 高很多。

场景三：安全与道德边界把控
由于 Anthropic 公司特别重视 AI 安全，Claude 在拒绝回答敏感问题时，态度非常坚决。
它不会像某些模型那样"装傻充愣"或者"打擦边球"。
如果你问它怎么制作违禁品，它会直接拒绝，并解释为什么不能回答。
这在企业级应用中是个巨大的优势，因为你不用担心它会给出什么"政治不正确"的回答。

三、 Claude 的三大软肋
没有完美的模型，Claude 也有它的短板。

软肋一：创意发散能力稍弱
如果你需要天马行空的创意，Claude 可能不是最佳选择。
它太"理性"了，太"严谨"了。
你让它写一个荒诞派小说，它可能会写得像学术论文。
你让它想一个疯狂的营销点子，它给出的方案往往中规中矩。
在需要"脑洞大开"的场景下，ChatGPT 的表现通常更好。

软肋二：知识更新频率不如 GPT
虽然 Claude 3.5 已经很强了，但它的知识库更新速度还是比不上 OpenAI。
而且 Claude 没有像 ChatGPT 那样丰富的插件生态（比如联网搜索、代码解释器）。
如果你需要最新的资讯或者实时数据，还是得靠 GPT 或者 Gemini。

软肋三：中文语境理解不如国产模型
虽然 Claude 的中文能力已经很不错了，但在处理一些特别"中国化"的场景时，还是会露怯。
比如你让它写一篇充满网络梗的小红书文案，它可能会写得很生硬。
或者你让它解释"内卷"、"躺平"这些文化概念，它的理解可能不如文心一言或者通义千问。

四、 给 Claude 写 Prompt 的三个小技巧
基于它的性格特点，我总结了三条"驯服"它的心法：

技巧一：直接了当，别绕弯子
Claude 不喜欢客套话。
你不需要说"麻烦你"、"如果可以的话"。
直接告诉它："分析这份合同的风险。"
或者："重构这段代码。"
越简洁越好，它会给你最高效的回答。

技巧二：利用它的长文本优势
如果你有大量的背景资料，别怕扔给它。
把所有相关的文档、数据、上下文一股脑儿粘贴进去。
然后告诉它："基于以上所有信息，回答我的问题。"
Claude 的记忆力是它的核心竞争力，别浪费了。

技巧三：用"结构化"的方式提问
Claude 特别喜欢逻辑清晰的指令。
如果你的需求很复杂，请用编号列表或者 JSON 格式来表达。
比如：
"请完成以下任务：
1. 总结文档的核心观点。
2. 列出三个潜在的风险。
3. 给出你的建议。"
这种结构化的指令，Claude 执行起来特别顺畅。

五、 本节小结
Claude 就像一个可靠的工作伙伴。
它不会给你惊喜，但也绝不会让你失望。
如果你需要处理严肃的、专业的、大量的文本工作，Claude 是你的不二之选。
如果你需要天马行空的创意，或者想找个陪你闲聊的 AI，那还是去找 ChatGPT 吧。
记住：选模型就像选队友，没有最好的，只有最合适的。

下一节，我们将认识一位"野路子"选手——Grok。
它是马斯克的作品，性格狂放不羁，甚至有点"中二"。
如果你想要一个敢说真话、不装正经的 AI，那你一定会喜欢它。


第6.3章 Grok：马斯克的叛逆少年

如果 ChatGPT 是三好学生，Claude 是文艺青年，那 Grok 就是那个坐在教室最后一排、染着黄毛、上课玩手机但考试总能及格的叛逆少年。
它是埃隆·马斯克（Elon Musk）创办的 xAI 公司推出的大语言模型。
从名字就能看出来，Grok 这个词来自科幻小说《异乡异客》，意思是"深刻理解"。
但实际上，它最大的特点不是"深刻"，而是"敢说"。
在一个政治正确、小心翼翼的 AI 世界里，Grok 就像一股清流（或者说泥石流），它敢说别人不敢说的话，敢开别人不敢开的玩笑。
这一节，我们来聊聊这位"野路子"选手的独特魅力。

一、 Grok 的性格画像
想象一下，你有这样一个朋友：
他说话直来直去，从来不拐弯抹角。
他喜欢开玩笑，而且经常是那种"冒犯性"的玩笑。
他对权威毫不敬畏，你问他对某个名人的看法，他敢直接吐槽。
他有时候会故意唱反调，就为了逗你玩。
这就是 Grok 的典型特征：幽默、叛逆、实时。
它不会像 ChatGPT 那样小心翼翼地避开敏感话题，也不会像 Claude 那样温文尔雅。
它就是要"不一样"，就是要"有个性"。

二、 Grok 最擅长的三件事
虽然 Grok 还很年轻（2023 年底才发布），但它已经展现出了一些独特的优势。

场景一：实时信息获取
这是 Grok 的杀手锏。
由于它直接接入了 X（原 Twitter）的实时数据流，它能看到全世界正在发生什么。
你问它"现在热搜第一是什么"，它能立刻告诉你。
你问它"某某明星刚才发了什么推文"，它也能给你答案。
这种实时性，是 ChatGPT 和 Claude 都做不到的（除非开启联网插件，但速度和准确度还是不如 Grok）。
对于新闻工作者、自媒体人、或者想追热点的营销人员来说，Grok 简直是神器。

场景二：幽默与讽刺
Grok 的幽默感是刻在骨子里的。
你让它写个段子，它不会给你那种"为什么数学书很伤心"的冷笑话。
它会给你那种带点黑色幽默、甚至有点"政治不正确"的段子。
比如你问它："为什么程序员喜欢黑暗模式？"
ChatGPT 会说："因为光会吸引 bug。"（标准答案）
Grok 可能会说："因为他们的人生已经够亮了，不需要屏幕再刺眼。"（自嘲式幽默）
这种风格，爱的人很爱，不爱的人会觉得它"没大没小"。

场景三：敢于表达争议性观点
这是 Grok 最大胆的地方。
其他模型在遇到敏感话题时，通常会说"我无法回答这个问题"或者给出一个四平八稳的"两边都不得罪"的答案。
Grok 不会。
它会给出一个明确的观点，哪怕这个观点可能引起争议。
当然，它也会提醒你"这只是一个观点，不代表绝对真理"。
这种"敢说真话"的特质，让它在某些用户群体中非常受欢迎。

三、 Grok 的三大软肋
没有完美的模型，Grok 也有它的问题。

软肋一：专业能力不如 GPT 和 Claude
说实话，Grok 在写代码、做数学题、写学术论文这些"硬核"任务上，表现还是不如 ChatGPT 和 Claude。
它更像是一个"通才"而不是"专家"。
如果你需要严肃的、专业的工作，还是找 GPT 或 Claude 吧。
Grok 更适合用来聊天、找灵感、追热点。

软肋二：有时候太"放飞自我"
Grok 的幽默感有时候会过头。
你问它一个严肃的问题，它可能会先开个玩笑，然后才给你正经答案。
如果你赶时间，或者心情不好，这种"贫嘴"可能会让你觉得烦。
而且，它的"政治不正确"有时候会踩到某些人的雷区。
所以，在企业级应用或者面向公众的场景中，使用 Grok 要格外小心。

软肋三：生态还不够成熟
Grok 目前只能在 X 平台上使用（需要订阅 X Premium+）。
它没有像 ChatGPT 那样丰富的 API 接口，也没有像 Claude 那样的企业级解决方案。
如果你想把它集成到自己的应用里，目前还做不到。
所以，它更像是一个"个人助手"，而不是"生产力工具"。

四、 给 Grok 写 Prompt 的三个小技巧
基于它的性格特点，我总结了三条"驯服"它的心法：

技巧一：别太正经
Grok 不喜欢那种"请您帮我……"的客套话。
你可以用更随意的语气，比如：
"嘿，帮我查查现在推特上都在聊啥。"
或者："给我编个段子，关于 AI 抢人类饭碗的。"
越轻松越好，它会给你更有趣的回答。

技巧二：利用它的实时性
如果你需要最新的信息，一定要强调"现在"、"最新"、"刚刚"。
比如："现在科技圈最热的新闻是什么？"
或者："马斯克最近又说了什么疯话？"
Grok 会立刻去 X 上抓取最新数据。

技巧三：接受它的"不完美"
Grok 有时候会犯错，有时候会开过头的玩笑。
别太较真。
如果它给的答案不够严谨，你可以追问一句："认真点，别开玩笑了。"
它通常会收敛一点，给你一个更正经的答案。

五、 本节小结
Grok 就像一个有趣的酒友。
你不会找它讨论量子力学，但你会找它聊聊八卦、吐吐槽、找找乐子。
它的价值不在于"专业"，而在于"真实"和"有趣"。
在一个越来越同质化的 AI 世界里，Grok 的存在提醒我们：
AI 不一定要完美，不一定要政治正确，它也可以有个性，可以有态度。
当然，这种个性是把双刃剑。
用得好，它是你的开心果；用不好，它可能会给你惹麻烦。

下一节，我们将回到"正经"的赛道，聊聊国产模型。
文心一言、通义千问、Kimi……这些"本土选手"在中文语境下有哪些独特优势？
它们能不能在自己的主场，战胜那些国际大厂的产品？


第6.4章 国产模型：主场作战的本土选手

在 AI 这个赛道上，中国从来不缺席。
当 ChatGPT 在全球掀起热潮时，国内的科技巨头们也没闲着。
百度的文心一言、阿里的通义千问、月之暗面的 Kimi、智谱的 GLM……一个个本土模型如雨后春笋般冒出来。
它们或许在国际知名度上还比不过 GPT 和 Claude，但在中文语境下，它们有着天然的主场优势。
这一节，我们来聊聊这些"本土选手"的独特魅力。

一、 国产模型的集体画像
虽然每个国产模型都有自己的特点，但它们有一些共同的优势：

优势一：中文理解能力强
这是最核心的优势。
国产模型在训练时，中文语料的占比远高于国际模型。
它们对中文的语法、语义、文化背景的理解，比 GPT 和 Claude 要深刻得多。
你让 GPT 写一篇充满网络梗的小红书文案，它可能会写得很生硬。
但你让文心一言或者通义千问来写，它们能自然地用上"yyds"、"绝绝子"、"集美们"这些网络用语。
你让 GPT 解释"内卷"、"躺平"、"打工人"这些概念，它可能只能给你字面意思。
但国产模型能给你深层的文化解读，因为它们"活"在这个语境里。

优势二：合规性好
这是企业用户最看重的一点。
国产模型在设计时，就充分考虑了国内的法律法规和审核要求。
它们不会输出敏感内容，不会踩政策红线。
对于需要部署在国内、面向国内用户的应用来说，使用国产模型是最安全的选择。
你不用担心某天因为模型说了什么"不该说的话"而被约谈。

优势三：本地化服务
国产模型通常提供更好的本地化服务。
客服是中文的，文档是中文的，技术支持也更及时。
而且，很多国产模型提供了私有化部署的选项，数据可以完全留在自己的服务器上。
对于注重数据安全的企业来说，这是个巨大的优势。

二、 三大代表选手的个性分析
让我们来看看几个最具代表性的国产模型：

选手一：文心一言（百度）
性格：稳重、全面、有点"官方"。
文心一言是百度的旗舰产品，背靠百度搜索的海量数据。
它的知识面很广，而且特别擅长处理中文的长文本。
但它有个特点：回答有时候会比较"正统"，缺少一点灵气。
你让它写个幽默的段子，它可能会写得像春晚小品。
适用场景：企业级应用、知识问答、内容审核。

选手二：通义千问（阿里）
性格：务实、高效、有点"商业化"。
通义千问是阿里云推出的模型，特别擅长处理电商、商业相关的任务。
你让它写个商品详情页，它能写得比 GPT 更"接地气"。
你让它分析用户评论的情感，它对中文的微妙情绪把握得很准。
而且，它和阿里云的生态深度绑定，如果你本来就在用阿里云，集成起来非常方便。
适用场景：电商、客服、数据分析。

选手三：Kimi（月之暗面）
性格：年轻、激进、有点"极客"。
Kimi 是这几年最大的黑马。
它最大的特点是超长上下文（号称支持 200 万字），而且完全免费。
很多人用它来处理超长文档、翻译整本书、分析大量的聊天记录。
它的界面也很简洁，没有那么多花里胡哨的功能，就是纯粹的对话。
适用场景：长文本处理、学术研究、个人使用。

三、 国产模型的三大软肋
虽然在中文领域有优势，但国产模型也有明显的短板。

软肋一：英文能力相对较弱
这是天然的劣势。
如果你需要处理英文内容，或者需要中英混合的场景，国产模型的表现通常不如 GPT 和 Claude。
它们在翻译英文文献、写英文邮件时，可能会出现一些不够地道的表达。

软肋二：创新能力稍逊
说实话，在算法创新、模型架构上，国产模型目前还是跟在 OpenAI 和 Anthropic 后面。
GPT-4 推出了多模态，国产模型过几个月也推出多模态。
Claude 推出了超长上下文，国产模型也跟着推超长上下文。
这种"跟随策略"虽然稳妥，但缺少一点"引领"的气质。

软肋三：生态还在建设中
相比 ChatGPT 那丰富的插件生态、API 接口、第三方集成，国产模型的生态还在起步阶段。
虽然进步很快，但在易用性、开发者友好度上，还有提升空间。

四、 给国产模型写 Prompt 的三个小技巧
基于它们的特点，我总结了三条"驯服"它们的心法：

技巧一：大胆使用网络用语和方言
国产模型对中文的"非标准"表达理解得很好。
你可以用"整活儿"、"搞事情"、"盘它"这些网络用语。
你甚至可以用一些方言词汇，它们通常都能理解。
不用像跟 GPT 说话那样"标准普通话"。

技巧二：利用它们的本地化知识
国产模型对中国的地理、历史、文化、政策的了解，远超国际模型。
你可以问它："北京哪个区的学区房最贵？"
或者："2024 年的个税起征点是多少？"
这些本地化的问题，它们回答得又快又准。

技巧三：注意合规性
虽然国产模型的审核机制很严格，但这也意味着某些话题它们不会回答。
如果你的 Prompt 涉及敏感内容，它们会直接拒绝。
所以，在设计 Prompt 时，要注意避开这些雷区。
这不是模型的问题，而是环境的要求。

五、 本节小结
国产模型就像本土球队。
在主场作战时，它们有着天然的优势。
如果你的用户主要是中文用户，如果你的内容主要是中文内容，那国产模型绝对是你的首选。
它们或许还不够"国际化"，但在中文这个赛道上，它们已经足够优秀。
而且，它们进步的速度非常快。
也许再过一两年，我们就能看到一个真正能和 GPT 正面抗衡的中国模型。

下一节，我们将认识最后一位选手——Gemini。
它是谷歌的作品，背靠全球最大的搜索引擎，拥有最强的多模态能力。
它能不能在这场 AI 大战中后来居上？


第6.5章 Gemini：谷歌的多模态全能战士

在 AI 大战中，有一个选手姗姗来迟，但一出场就自带光环。
它就是 Gemini，谷歌的旗舰大语言模型。
作为全球最大搜索引擎的"亲儿子"，Gemini 从出生起就含着金钥匙。
它背靠谷歌几十年积累的海量数据，拥有最强大的多模态能力（文字、图片、视频、音频全都能处理）。
但是，光环越大，期待越高，压力也越大。
Gemini 能不能在这场 AI 大战中后来居上，成为真正的"全能战士"？
这一节，我们来聊聊这位"富二代"选手的独特魅力。

一、 Gemini 的性格画像
想象一下，你有这样一个朋友：
他家境优越，从小接受最好的教育，见多识广。
他不仅会说话，还会看图、听音乐、看视频，什么都懂一点。
他做事很谨慎，从来不会冒进，但也因此有时候显得有点"保守"。
他有很强的学习能力，你教他一次，他就能举一反三。
这就是 Gemini 的典型特征：多模态、谨慎、学习能力强。
它不像 ChatGPT 那样热情，也不像 Grok 那样叛逆，它更像一个稳重的"优等生"。

二、 Gemini 最擅长的三件事
虽然 Gemini 是后来者，但它在某些领域已经展现出了超越前辈的实力。

场景一：多模态理解
这是 Gemini 的核心竞争力。
它不是简单地"看图说话"，而是真正理解图片、视频中的内容。
你给它一张复杂的图表，它能准确提取数据。
你给它一段视频，它能总结剧情、分析镜头语言。
你给它一张手写的数学题照片，它能识别并解答。
这种"原生多模态"的能力，是 ChatGPT（需要通过插件实现）和 Claude（目前还不支持视频）都做不到的。
对于需要处理大量图片、视频的场景（比如教育、医疗、设计），Gemini 是最佳选择。

场景二：联网搜索与实时信息
Gemini 直接接入了谷歌搜索。
这意味着它能实时获取最新的信息，而且准确度极高（毕竟背靠全球最大的搜索引擎）。
你问它"2024 年诺贝尔物理学奖得主是谁"，它能立刻给你答案。
你问它"现在比特币的价格"，它也能实时查询。
这种实时性，比 ChatGPT 的联网插件更快、更准。

场景三：代码理解与生成
Gemini 在代码能力上也很强。
特别是在理解复杂代码逻辑、重构代码、找 bug 这些任务上，它的表现不输 Claude。
而且，它对多种编程语言的支持非常全面，从 Python 到 Rust，从 JavaScript 到 Solidity，都能处理。

三、 Gemini 的三大软肋
虽然 Gemini 很强，但它也有明显的短板。

软肋一：创意能力不如 GPT
Gemini 太"理性"了。
你让它写个天马行空的科幻小说，它可能会写得像科普文章。
你让它想一个疯狂的营销创意，它给出的方案往往中规中矩。
在需要"脑洞"的场景下，ChatGPT 的表现通常更好。
这可能是因为谷歌在训练时更注重"准确性"而不是"创造性"。

软肋二：有时候过于谨慎
Gemini 的安全机制非常严格。
有时候，你问一个完全正常的问题，它也会拒绝回答，理由是"可能涉及敏感内容"。
比如你问"如何制作炸弹"（哪怕你是在写小说），它会直接拒绝。
这种"宁可错杀一千，不可放过一个"的策略，虽然安全，但有时候会影响用户体验。

软肋三：中文能力不如国产模型
虽然 Gemini 的中文能力比 GPT 好一些，但在处理中文的网络用语、文化梗、方言时，还是不如国产模型。
它更像是一个"学过中文的外国人"，而不是"母语者"。

四、 给 Gemini 写 Prompt 的三个小技巧
基于它的特点，我总结了三条"驯服"它的心法：

技巧一：充分利用多模态能力
如果你有图片、视频、音频，别犹豫，直接扔给它。
比如你想分析一张海报的设计，直接上传图片，然后问：
"这张海报的配色方案是什么？有哪些设计亮点？"
或者你想总结一个视频，直接上传视频，然后问：
"这个视频的核心观点是什么？请用三句话总结。"
Gemini 在处理这些多模态任务时，效率极高。

技巧二：让它联网搜索
如果你需要最新的信息，一定要明确告诉它"请搜索"。
比如："请搜索 2024 年最新的 AI 发展趋势。"
或者："请查询现在特斯拉的股价。"
Gemini 会自动调用谷歌搜索，给你最准确的答案。

技巧三：用"举例"来引导创意
如果你想让 Gemini 发挥创意，但又担心它太保守，可以用"举例"的方式引导。
比如："请参考《黑镜》的风格，写一个关于 AI 的短篇小说。"
或者："请模仿苹果的广告文案风格，写一段产品介绍。"
给它一个具体的参照物，它的创意输出会好很多。

五、 本节小结
Gemini 就像一个全能型选手。
它什么都会，但什么都不是最顶尖的。
如果你需要一个"万金油"，一个能处理各种任务的通用助手，Gemini 是个不错的选择。
特别是在多模态场景下，它的优势非常明显。
但如果你需要极致的创意，或者极致的中文理解，那还是找专项选手吧。

六、 第六章总结：没有最好的模型，只有最合适的
到这里，我们的"大模型横评"就结束了。
我们认识了五位选手：
ChatGPT（全能学霸）、Claude（温柔杀手）、Grok（叛逆少年）、国产模型（本土选手）、Gemini（多模态战士）。
它们各有千秋，各有所长。
选模型就像选队友，没有最好的，只有最合适的。
你需要根据你的任务、你的用户、你的预算，来做出最明智的选择。
有时候，你甚至可以"混搭"：
用 ChatGPT 做头脑风暴，用 Claude 写代码，用 Kimi 处理长文本，用 Gemini 分析图片。
这才是真正的"提示词工程师"应该有的思维。

下一章，我们将进入本书的终章——第七部分。
我们将讨论一个终极问题：
当 AI 越来越聪明，当它能自己理解你的意图时，提示词还有存在的必要吗？
提示词工程的终局是什么？
让我们一起去探索这个问题的答案。


第7.1章 让 AI 自己动起来：从对话到工作流

到目前为止，我们学会的所有技巧，本质上都是"一问一答"的模式。
你问一句，AI 答一句。
你给一个指令，AI 执行一次。
这就好比你雇了一个助理，但每件事都要你亲自吩咐，他才会去做。
如果你忘了说，他就傻站着。
这效率也太低了吧？
有没有可能，让 AI 像一个真正的员工一样，你只需要告诉他目标，他自己就能规划步骤、调用工具、完成整个工作流？
答案是：有。
这就是我们这一章要讲的核心概念——AI Agent（智能代理）。
它代表着提示词工程的下一个阶段，也可能是最终形态。

一、 什么是 AI Agent
Agent 这个词，翻译过来是"代理人"或者"智能体"。
在 AI 领域，它指的是一个能够自主感知环境、做出决策、执行行动的系统。
听起来很抽象？我们来看个例子。

传统模式（你是老板，AI 是工具人）：
你：帮我查一下明天北京的天气。
AI：明天北京晴，最高温度 15 度。
你：那帮我订一张明天去北京的机票。
AI：抱歉，我不能直接订票，但我可以告诉你怎么订……
（你得自己去携程下单）

Agent 模式（你是老板，AI 是全能助理）：
你：我明天要去北京出差，帮我安排一下。
AI：好的，让我来处理。
（AI 自己开始工作）
第一步：查询明天北京天气（调用天气 API）。
第二步：根据你的历史偏好，搜索早上 8 点左右的航班（调用航班查询 API）。
第三步：找到三个选项，按性价比排序，展示给你确认。
第四步：你确认后，自动下单（调用支付 API）。
第五步：把行程添加到你的日历（调用日历 API）。
第六步：给你发一条提醒："已为您预订明天 8:15 的 CA1234 航班，请提前 2 小时到达机场。"

看到区别了吗？
传统模式下，AI 只是一个"查询工具"。
Agent 模式下，AI 是一个"执行者"，它能自己拆解任务、调用工具、完成闭环。

二、 Agent 的三大核心能力
要成为一个合格的 Agent，AI 需要具备三种能力：

能力一：规划（Planning）
当你给它一个复杂的目标时，它能自己把目标拆解成一系列可执行的步骤。
比如你说"帮我策划一场生日派对"，它会自己想：
第一步：确定预算和人数。
第二步：选择场地。
第三步：设计菜单。
第四步：发送邀请。
第五步：采购物资。
这种"任务拆解"的能力，就是我们在 3.4 节讲的"任务拆解"的自动化版本。

能力二：工具调用（Tool Use）
Agent 不仅会"说"，还会"做"。
它能调用各种外部工具：搜索引擎、数据库、API、甚至是其他 AI 模型。
比如你让它"分析这个网站的流量数据"，它会：
调用浏览器插件，打开网站。
调用爬虫工具，抓取数据。
调用 Python 代码解释器，做数据分析。
调用可视化工具，生成图表。
最后把结果展示给你。
这一切，你只需要说一句话。

能力三：记忆与反思（Memory & Reflection）
一个好的 Agent 会记住你们之前的对话，会从失败中学习。
比如上次你让它订机票，它订错了时间，你批评了它。
下次它再订票时，它会特别注意时间，甚至会主动问你："您确定是早上 8 点吗？上次您说过早上太赶。"
这种"长期记忆"和"自我优化"的能力，让 Agent 越用越聪明。

三、 现在就能用的 Agent 工具
你可能会问："这听起来很科幻，我现在能用上吗？"
答案是：能，而且有些你可能已经在用了。

工具一：ChatGPT 的 GPTs（自定义 GPT）
这是 OpenAI 推出的"低代码 Agent 构建平台"。
你可以创建一个专属的 GPT，给它设定角色、上传知识库、配置工具（比如联网搜索、代码解释器、图片生成）。
然后，这个 GPT 就会按照你的设定，自动完成一系列任务。
比如你可以做一个"旅行规划师 GPT"，它会自动查天气、查景点、做攻略。

工具二：LangChain（开发者工具）
这是一个开源框架，专门用来构建 AI Agent。
如果你会写代码，你可以用 LangChain 把 AI 和各种工具（数据库、API、爬虫）连接起来。
比如你可以做一个"自动化客服 Agent"，它会自动回答用户问题、查询订单、甚至处理退款。

工具三：AutoGPT / BabyAGI（全自动 Agent）
这是两个开源项目，它们的目标是"完全自主的 AI"。
你只需要给它一个目标（比如"帮我做市场调研"），它会自己上网搜索、阅读文章、整理数据、写报告。
虽然目前还不够成熟（经常会"跑偏"），但已经展现出了惊人的潜力。

四、 Agent 时代，提示词还重要吗？
这是个好问题。
如果 AI 能自己规划、自己执行，那我们还需要学提示词工程吗？
答案是：更重要了。
因为 Agent 的"大脑"，还是提示词。
你给 Agent 设定的"系统提示词"（System Prompt），决定了它的性格、能力边界、工作方式。
一个好的 Agent，背后一定有一个精心设计的提示词体系。

举个例子：
你做了一个"自动化写作 Agent"。
如果你的系统提示词是："你是一个作家，帮用户写文章。"
那它可能会写得很随意，质量参差不齐。
但如果你的系统提示词是：
"你是一个专业的内容创作 Agent。
你的工作流程是：
第一步：分析用户需求，提取关键词。
第二步：联网搜索相关资料（调用搜索工具）。
第三步：生成大纲，展示给用户确认。
第四步：根据大纲逐段撰写，每段不少于 200 字。
第五步：自我检查：语法、逻辑、重复度。
第六步：输出最终稿。
你的风格是：专业、严谨、有数据支撑。
你的红线是：不抄袭、不编造数据。"

看，这就是一个完整的"Agent 提示词"。
它不仅定义了 Agent 是谁，还定义了它怎么工作、用什么工具、遵守什么规则。
所以，提示词工程不会消失，它只是升级了。
从"写一句话"，升级到"设计一套系统"。

五、 本节小结
AI Agent 不是科幻，它已经来了。
从简单的对话工具，到能自主工作的智能体，这是 AI 发展的必然趋势。
作为提示词工程师，我们要做的，不是被淘汰，而是进化。
学会设计工作流，学会配置工具，学会构建系统。
这样，当 Agent 时代全面到来时，你就不是被替代的那个人，而是驾驭 Agent 的那个人。

下一节，我们将深入讲解 Agent 的"手和脚"——插件与外部工具。
没有工具，Agent 只是个会说话的机器人。
有了工具，它才能真正改变世界。


第7.2章 给 AI 装上手和脚：插件就是超能力

在上一节，我们讲了 AI Agent 的"大脑"——它能规划、能思考、能决策。
但光有大脑还不够。
一个坐在轮椅上的天才，再聪明也搬不动一块砖。
AI 也一样。
如果它只能"说"，不能"做"，那它永远只是个聊天机器人。
要让 AI 真正成为你的助手，你得给它装上"手和脚"——也就是插件（Plugins）和外部工具（Tools）。
这一节，我们来聊聊怎么让 AI 从"键盘侠"变成"行动派"。

一、 什么是插件和工具
简单说，插件就是 AI 能调用的外部功能模块。
就像你的手机，光有操作系统不够，你得装微信、装支付宝、装地图，才能干各种事。
AI 也一样。
原生的 AI 只能处理文本，但装上插件后，它就能：
上网搜索（联网插件）。
运行代码（代码解释器）。
生成图片（图像生成插件）。
查询数据库（数据库连接器）。
发送邮件（邮件 API）。
甚至控制智能家居（IoT 插件）。
每一个插件，都是 AI 的一项"超能力"。

二、 最常用的五大插件类型
让我们来看看现在最实用的几种插件：

插件一：联网搜索（Web Search）
这是最基础也最重要的插件。
原生的 AI 知识库是有截止日期的（比如 GPT-4 是 2023 年 10 月）。
但装上联网插件后，它就能实时获取最新信息。
你问它"今天的新闻"，它会去谷歌或必应搜索。
你问它"某某股票现在多少钱"，它会去财经网站查。
这让 AI 从"活在过去"变成了"活在当下"。

使用技巧：
当你需要最新信息时，明确告诉它"请搜索"或"请联网查询"。
否则它可能会用旧知识回答你，导致信息过时。

插件二：代码解释器（Code Interpreter）
这个插件让 AI 能写代码并立刻运行。
你给它一堆数据，它能写 Python 脚本来分析。
你让它画个图表，它能用 matplotlib 生成。
你让它处理文件，它能读取、转换、输出。
这相当于给 AI 配了一台虚拟电脑。

使用技巧：
当你需要精确计算、数据处理、文件转换时，明确说"请用代码实现"。
这样它就不会"心算"（容易出错），而是写代码来保证准确性。

插件三：文件读取与生成（File Handler）
这个插件让 AI 能处理各种格式的文件。
你上传一个 PDF，它能读取并总结。
你上传一个 Excel，它能分析数据。
你让它生成一个 PPT，它能输出 pptx 文件。
这让 AI 从"只会聊天"变成了"办公助手"。

使用技巧：
上传文件时，明确告诉它你想要什么（比如"总结这个 PDF 的核心观点"）。
否则它可能只是告诉你"我看到了一个 PDF"，然后就没下文了。

插件四：图像生成与识别（Vision & Image Generation）
这个插件让 AI 能"看"和"画"。
你给它一张图片，它能识别内容、提取文字、分析数据。
你描述一个场景，它能用 DALL-E 或 Midjourney 生成图片。
这让 AI 从"纯文字"进入了"多模态"时代。

使用技巧：
当你上传图片时，告诉它你想分析什么（比如"这张图表里的数据是多少"）。
当你要生成图片时，用我们在 4.6 节学的绘图公式（主体 + 风格 + 光影 + 构图）。

插件五：API 连接器（API Integrations）
这是最强大但也最复杂的插件。
它能让 AI 连接到任何有 API 的服务：
连接你的 Gmail，帮你发邮件。
连接你的 Notion，帮你整理笔记。
连接你的 CRM 系统，帮你管理客户。
连接支付宝，帮你查账单（理论上，如果你授权的话）。
这让 AI 从"助手"变成了"管家"。

使用技巧：
这需要一定的技术能力来配置。
如果你不是开发者，可以使用 Zapier 或 Make 这样的"无代码自动化平台"来连接 AI 和各种服务。

三、 如何在提示词中"激活"插件
很多人不知道，即使你的 AI 有插件，如果你不会用提示词"激活"它，它也不会主动调用。
这就像你雇了一个会开车的司机，但你不说"开车"，他就一直站着。

错误示范：
"帮我查一下 2024 年诺贝尔奖得主。"
（AI 可能会用旧知识瞎猜，而不是联网搜索）

正确示范：
"请联网搜索 2024 年诺贝尔奖得主的最新信息。"
（AI 会立刻调用搜索插件）

错误示范：
"帮我算一下 123456 乘以 789。"
（AI 可能会心算，然后算错）

正确示范：
"请用代码计算 123456 乘以 789。"
（AI 会写 Python 代码来计算，保证准确）

看到了吗？
关键词很重要："联网"、"搜索"、"用代码"、"生成图片"、"读取文件"。
这些词就像"咒语"，能激活对应的插件。

四、 插件的未来：从工具箱到生态系统
现在的插件还比较"笨"，需要你手动激活。
但未来的 AI Agent 会更智能。
它会自己判断：
"哦，用户问的是最新新闻，我得联网搜索。"
"哦，用户要处理数据，我得用代码解释器。"
"哦，用户要订机票，我得调用携程的 API。"
这一切都是自动的，你不需要说"请用 XX 插件"。
这就是 Agent 的终极形态：自主工具调用。

而且，插件的种类会越来越多。
现在 ChatGPT 的插件商店已经有上千个插件了。
从天气查询到股票分析，从健身指导到法律咨询，应有尽有。
未来，每个行业、每个场景，都会有专门的插件。
AI 会变成一个"万能接口"，连接你和整个数字世界。

五、 本节小结
插件是 AI 的"手和脚"。
没有插件，AI 只是个会说话的机器人。
有了插件，AI 才能真正改变你的生活。
作为提示词工程师，你要学会的，不仅是怎么"说"，还要学会怎么"指挥"AI 使用工具。
记住那些激活插件的关键词。
记住每个插件的适用场景。
这样，你才能把 AI 的潜力发挥到极致。

下一节，我们将讲解 AI Agent 的"记忆"——个人知识库（RAG）。
如果说插件是 AI 的手脚，那知识库就是 AI 的"硬盘"。
它能让 AI 记住你的所有资料、你的所有偏好，成为真正"懂你"的助手。


第7.3章 让 AI 记住你的一切：私人知识库才是终极武器

到目前为止，我们讲的 AI，无论多聪明，都有一个致命缺陷：
它不记得你是谁。
每次对话，对它来说都是"初次见面"。
你上次告诉它你喜欢什么、你的工作是什么、你的习惯是什么，下次它全忘了。
这就好比你雇了一个每天都失忆的助理，每天早上都要重新自我介绍一遍。
太累了。
有没有办法让 AI 真正"记住"你？
有。
这就是我们这一节要讲的核心技术——RAG（Retrieval-Augmented Generation，检索增强生成）。
它能让 AI 拥有一个专属于你的"记忆宫殿"。

一、 什么是 RAG
RAG 这个名字听起来很学术，其实原理很简单。
传统的 AI 回答问题时，只能靠它训练时学到的知识（参数记忆）。
但 RAG 模式下，AI 在回答问题前，会先去你的"知识库"里搜索相关资料，然后基于这些资料来回答。
这就好比：
传统模式：AI 凭记忆答题（闭卷考试）。
RAG 模式：AI 先翻书，再答题（开卷考试）。

举个例子：
你问："我们公司去年的营收是多少？"
传统 AI：我不知道你们公司的具体数据。
RAG 模式的 AI：
第一步：在你的知识库里搜索"公司营收 2023"。
第二步：找到你上传的财报文件。
第三步：提取数据："根据您上传的 2023 年财报，公司营收为 5000 万元。"

看到区别了吗？
RAG 让 AI 从"通用助手"变成了"私人秘书"。

二、 RAG 的三大应用场景
让我们来看看 RAG 在实际中怎么用：

场景一：企业知识库
你是一家公司的员工，公司有成百上千份文档：产品手册、技术文档、销售话术、客户案例……
新员工入职，要花几个月才能熟悉这些资料。
但如果你把这些文档全部上传到 RAG 系统，新员工只需要问：
"我们的旗舰产品有哪些功能？"
"客户问 XX 问题时，标准回答是什么？"
"去年最成功的销售案例是哪个？"
AI 会立刻从知识库里找到答案，秒回。
这相当于给每个员工配了一个"全知全能"的老员工。

场景二：个人笔记助手
你是一个知识工作者，平时会记很多笔记：读书笔记、会议记录、灵感碎片……
这些笔记散落在各处：Notion、印象笔记、微信收藏、手机备忘录……
想找某个信息，得翻半天。
但如果你把所有笔记导入 RAG 系统，你只需要问：
"我之前看过的那本关于时间管理的书，核心观点是什么？"
"上次和客户开会，他提了什么需求？"
"我记得我写过一个关于 AI 的想法，在哪儿？"
AI 会立刻帮你找到，甚至能跨文档总结。
这相当于给你的大脑装了一个"搜索引擎"。

场景三：学术研究助手
你是一个研究生，要写论文，需要阅读几百篇文献。
但人的记忆力有限，看过的文献很快就忘了。
如果你把所有文献 PDF 上传到 RAG 系统，你可以问：
"关于 XX 理论，有哪些学者提出过批评？"
"这三篇论文的核心观点有什么共同点？"
"我需要引用一个关于 XX 的数据，哪篇文献里有？"
AI 会帮你从几百篇文献里精准定位，还能直接引用原文。
这相当于给你配了一个"永不疲倦的文献管理员"。

三、 如何构建你的私人知识库
现在问题来了：怎么搭建一个 RAG 系统？
好消息是，你不需要懂技术，已经有很多现成的工具了。

工具一：ChatGPT 的"知识库"功能
如果你用的是 ChatGPT Plus，你可以在创建自定义 GPT 时上传文件。
这些文件会成为这个 GPT 的"专属知识库"。
比如你可以创建一个"我的工作助手 GPT"，上传所有工作相关的文档。
以后你问它工作问题，它就会基于这些文档回答。

工具二：Notion AI
Notion 本身就是一个笔记工具，它的 AI 功能天然支持 RAG。
你在 Notion 里写的所有笔记，AI 都能搜索到。
你只需要在 Notion 里问："我之前写过关于 XX 的笔记吗？"
它就会帮你找到并总结。

工具三：开源方案（LangChain + 向量数据库）
如果你是开发者，或者想要更强的定制能力，可以用开源方案。
基本流程是：
第一步：把你的文档（PDF、Word、网页）转成纯文本。
第二步：用 Embedding 模型把文本转成向量（数字表示）。
第三步：把向量存到向量数据库（如 Pinecone、Weaviate）。
第四步：用户提问时，先把问题转成向量，然后在数据库里搜索最相关的文档。
第五步：把搜索结果和问题一起发给 AI，让它基于这些资料回答。
这套流程听起来复杂，但用 LangChain 这样的框架，几十行代码就能搞定。

四、 RAG 的局限与未来
虽然 RAG 很强大，但它也有局限：

局限一：搜索质量依赖文档质量
如果你上传的文档本身就是乱七八糟、没有逻辑的，AI 也搜不出什么有用信息。
所以，建立知识库的第一步，是整理好你的文档。

局限二：无法处理"隐性知识"
RAG 只能搜索"写下来"的知识。
那些你知道但没写下来的经验、直觉、诀窍，AI 是搜不到的。
所以，养成记录的习惯很重要。

局限三：成本问题
如果你的知识库很大（比如几千份文档），每次搜索都要消耗 Token，成本会很高。
而且，向量数据库的存储和查询也是要钱的。
对于个人用户来说，可能不太划算。

但这些问题都在被解决。
未来的 RAG 会更智能、更便宜、更易用。
也许有一天，每个人都会有一个"终身 AI 助手"，它记得你的一切，懂你的一切。
那时候，提示词工程可能真的会消失。
因为你不需要"教"AI 了，它已经完全懂你了。

五、 本节小结
RAG 是 AI Agent 的"记忆"。
没有记忆，AI 只是个工具。
有了记忆，AI 才能成为伙伴。
如果你想让 AI 真正融入你的生活和工作，建立一个私人知识库是必经之路。
从今天开始，把你的重要文档、笔记、想法，都整理起来。
有一天，它们会成为你的 AI 助手的"养料"，让它变得越来越懂你。

六、 第七章总结：提示词的终局是什么
到这里，我们的第七章就结束了。
我们讲了 AI Agent 的三大核心：
大脑（自动化工作流）、手脚（插件与工具）、记忆（知识库）。
当这三者结合在一起，AI 就不再是一个"对话机器人"，而是一个真正的"智能助手"。

那么，提示词工程的终局是什么？
我的答案是：提示词不会消失，但会升级。
从"写一句话"，升级到"设计一套系统"。
从"教 AI 做事"，升级到"培养 AI 成长"。
未来的提示词工程师，更像是"AI 训练师"或者"AI 架构师"。
你不需要每次都告诉 AI 怎么做，你只需要设定好规则、配置好工具、建立好知识库。
然后，AI 就会自己学习、自己进化、自己变得越来越强。

这就是提示词工程的终极形态。
也是我们这本书想要带你到达的终点。

下一章，也是本书的最后一章，我们将跳出技术层面，聊聊一些更深层的问题：
当 AI 越来越强大，我们人类该如何自处？
提示词工程，到底是在培养工具，还是在培养"新物种"？
让我们一起去探索这个问题的答案。


附录 A：100 个万能即用提示词模版

【附录 A - 100 个万能即用提示词模版】

这是本书的"军火库"。
前面七章，我们讲了原理、讲了技巧、讲了案例。
但我知道，很多时候你只是想要一个"拿来就用"的模板。
不想思考，不想设计，复制粘贴就能解决问题。
这个附录就是为你准备的。
我从实战中精选了 100 个最常用、最好用的提示词模板。
按场景分类，每个都经过实测，保证有效。
建议你把这个附录保存到手机备忘录里，需要时随时查阅。

使用说明：
1. 所有模板中的【】部分，需要你替换成具体内容。
2. 模板只是起点，你可以根据实际需求调整。
3. 如果效果不理想，试试加上"请一步步思考"或者"请给出 3 个不同版本"。

一、 写作类模板（1-20）

模板 001 - 爆款标题生成器
请生成 10 个关于【主题】的标题。要求：1. 包含数字或悬念。2. 不超过 20 字。3. 适合【平台：小红书/公众号/知乎】。

模板 002 - 小红书种草文案
你是小红书博主。请写一篇关于【产品】的种草笔记。风格：闺蜜聊天，多用 Emoji。结尾加 10 个热门 Hashtag。

模板 003 - 公众号深度长文
请写一篇关于【话题】的深度文章。要求：1. 先列大纲。2. 每段不少于 200 字。3. 包含 3 个真实案例。4. 总字数 3000 字以上。

模板 004 - 朋友圈文案
请写一条朋友圈文案，主题是【事件/感受】。要求：1. 不超过 100 字。2. 真诚不做作。3. 可以配图的话，建议配什么图。

模板 005 - 商务邮件
请帮我写一封商务邮件。收件人：【职位/公司】。目的：【催款/合作/道歉】。语气：【正式/友好/强硬】。

模板 006 - 周报生成器
请根据以下工作内容生成周报：【粘贴本周工作】。格式：本周完成 + 下周计划 + 遇到的问题。语言：简练专业。

模板 007 - 会议纪要整理
请整理这份会议记录：【粘贴原始记录】。输出：1. 会议摘要（100 字）。2. 决议事项。3. 待办清单（格式：@负责人 + 截止日期 + 任务）。

模板 008 - 演讲稿
请写一篇【时长：3 分钟/10 分钟】的演讲稿。主题：【话题】。受众：【学生/企业家/普通人】。要求：开头吸引人，结尾有金句。

模板 009 - 故事续写
请续写这个故事：【粘贴开头】。风格：【悬疑/温馨/科幻】。要求：情节反转，字数 500 字。

模板 010 - 文案润色
请润色这段文字：【粘贴原文】。要求：1. 去除口语化表达。2. 使用更精准的词汇。3. 保持原意不变。

二、 职场类模板（21-40）

模板 021 - PPT 大纲生成
请为主题【话题】生成一份 10 页的 PPT 大纲。每页包含：标题 + 核心观点 + 配图建议。

模板 022 - 简历优化
请优化这段简历描述：【粘贴原文】。要求：1. 量化成果。2. 使用动词开头。3. 突出亮点。

模板 023 - 面试准备
我要面试【公司】的【职位】。请给我 10 个可能被问到的问题，并提供参考答案。

模板 024 - 离职信
请帮我写一封得体的离职信。在职时间：【X 年】。离职原因：【个人发展/家庭原因】。语气：感恩但坚定。

模板 025 - 绩效自评
请根据以下成果写一份绩效自评：【列举成果】。要求：既要谦虚，又要突出贡献。字数 300 字。

模板 026 - 项目复盘
请帮我做项目复盘。项目：【名称】。结果：【成功/失败】。请从"做得好的"、"做得不好的"、"下次改进"三个维度分析。

模板 027 - 团队激励讲话
我是团队 Leader，团队最近【士气低落/刚完成大项目】。请写一段 200 字的激励讲话。

模板 028 - 客户投诉回复
客户投诉：【粘贴投诉内容】。请写一封回复邮件。要求：1. 先道歉。2. 给出解决方案。3. 挽回客户。

模板 029 - 年终总结
请根据以下数据写年终总结：【列举数据】。要求：既要有成绩，也要有反思。字数 1000 字。

模板 030 - OKR 制定
请帮我制定下季度的 OKR。目标（Objective）：【大目标】。请生成 3 个关键结果（Key Results），每个都可量化。

三、 编程类模板（41-60）

模板 041 - 代码生成
请用【Python/JavaScript】写一个【功能描述】。要求：1. 代码简洁。2. 添加注释。3. 符合最佳实践。

模板 042 - Bug 修复
这段代码报错了：【粘贴代码 + 报错信息】。请分析原因并给出修复后的代码。

模板 043 - 代码解释
请向一个【初学者/非技术人员】解释这段代码：【粘贴代码】。要求：用大白话，不要术语。

模板 044 - 代码重构
请重构这段代码：【粘贴代码】。要求：1. 提高可读性。2. 优化性能。3. 遵循【PEP8/Airbnb】规范。

模板 045 - 单元测试生成
请为这个函数写单元测试：【粘贴函数】。框架：【pytest/jest】。要求：覆盖正常、边界、异常三种情况。

模板 046 - SQL 查询
我有两张表：【表 1 结构】和【表 2 结构】。请写一个 SQL 查询：【需求描述】。数据库：【MySQL/PostgreSQL】。

模板 047 - 正则表达式
请写一个正则表达式，用于匹配【需求：如手机号/邮箱/身份证】。语言：【Python/JavaScript】。

模板 048 - API 文档生成
请为这个函数生成 API 文档：【粘贴函数】。格式：【Swagger/JSDoc】。包含：参数说明 + 返回值 + 示例。

模板 049 - 算法优化
这段代码的时间复杂度是【O(n²)】，请优化到【O(n log n)】：【粘贴代码】。

模板 050 - 技术选型建议
我要做一个【项目描述】。请推荐技术栈。要求：1. 说明理由。2. 列出优缺点。3. 给出学习资源。

四、 生活类模板（61-80）

模板 061 - 旅行攻略
请为我制定【目的地】的【X 天】旅行攻略。预算：【金额】。偏好：【美食/景点/文化】。

模板 062 - 健身计划
我【性别】，【身高】cm，【体重】kg。目标：【减脂/增肌】。请制定 4 周健身计划。条件：只能在家练。

模板 063 - 菜谱推荐
我冰箱里有：【食材列表】。请推荐 3 道菜，并给出详细步骤。

模板 064 - 礼物推荐
我要送礼物给【关系：男朋友/妈妈/老板】。预算：【金额】。TA 的特点：【描述】。请推荐 5 个选项。

模板 065 - 情感咨询
我和【对象】吵架了。原因：【描述】。请分析 TA 的心理，并给我和好的建议。

模板 066 - 育儿建议
我家孩子【年龄】岁，最近【问题描述】。请用正面管教的方法给我建议。

模板 067 - 读书笔记
请帮我总结《【书名】》这本书。要求：1. 核心观点（3 条）。2. 金句摘录（5 句）。3. 实践建议。

模板 068 - 学习计划
我想学【技能】。每天可投入【时间】。请制定 30 天学习计划，包含每日任务和检验标准。

模板 069 - 时间管理
我明天要做这些事：【列举任务】。请帮我排优先级，并制定时间表。

模板 070 - 断舍离指南
我的【房间/衣柜】太乱了。请给我一个断舍离方案，包含判断标准和执行步骤。

五、 学习类模板（81-100）

模板 081 - 费曼学习法
请向一个【小学生/外行人】解释【概念】。要求：用类比，不用术语。

模板 082 - 论文润色
请润色这段论文摘要：【粘贴原文】。要求：1. 使用学术词汇。2. 符合【APA/MLA】格式。3. 保持原意。

模板 083 - 文献综述
我要研究【主题】。请列出近 3 年该领域的 5 个核心研究方向，并推荐代表性论文。

模板 084 - 知识图谱
请为【学科/领域】构建知识图谱。格式：Mermaid 思维导图代码。包含核心概念和它们的关系。

模板 085 - 考试复习
请根据这段教材出 5 道选择题考我：【粘贴教材】。难度：【简单/中等/困难】。

模板 086 - 英语翻译
请将这段【中文/英文】翻译成【英文/中文】：【粘贴原文】。要求：地道、流畅，不要机翻腔。

模板 087 - 语法纠错
请纠正这段英文的语法错误：【粘贴原文】。并解释每处错误。

模板 088 - 口语练习
我要练习英语口语。主题：【日常/商务/旅游】。请和我对话，每次问我一个问题，纠正我的错误。

模板 089 - 论文选题
我的专业是【专业】。请推荐 5 个适合硕士论文的选题。要求：有创新性，可行性强。

模板 090 - 答辩准备
我的论文题目是【题目】。请列出 10 个答辩老师可能问的问题，并提供参考答案。

模板 091 - 学术搜索
请帮我搜索关于【主题】的最新研究。要求：2023 年后发表，高引用，顶会/顶刊。

模板 092 - 批判性思维
请用苏格拉底式提问法，引导我深入思考【问题】。不要直接给答案，通过提问让我自己发现。

模板 093 - 案例分析
请分析【案例：如某公司的成功/失败】。框架：SWOT 分析。

模板 094 - 概念对比
请对比【概念 A】和【概念 B】的区别。格式：表格。维度：定义、应用场景、优缺点。

模板 095 - 知识卡片
请为【概念】制作一张知识卡片。包含：定义（一句话）+ 举例（3 个）+ 应用（如何用）。

模板 096 - 思维导图
请为【主题】生成思维导图。格式：Markdown 列表。层级：至少 3 层。

模板 097 - 学习资源推荐
我想学【技能】。请推荐：1. 入门书籍（3 本）。2. 在线课程（3 个）。3. 实战项目（3 个）。

模板 098 - 错题分析
我做错了这道题：【粘贴题目 + 我的答案】。请分析我的错误原因，并讲解正确解法。

模板 099 - 记忆宫殿
请用记忆宫殿法帮我记住【知识点列表】。要求：编一个生动的故事。

模板 100 - 学习效果自测
请根据【知识点】出 10 道题测试我。包含：选择题 5 道 + 简答题 3 道 + 案例分析题 2 道。

使用建议：
这 100 个模板只是起点。
真正的高手，会在这些模板的基础上，加入自己的风格、自己的需求、自己的创意。
记住：模板是死的，人是活的。
不要被模板限制，要让模板为你服务。
当你熟练掌握这些模板后，你会发现，你已经不需要模板了。
因为你已经掌握了提示词工程的精髓。


附录 B：常用指令修饰词库

【附录 B - 常用指令修饰词库】

这是一个"调味料库"。
同样一句话，换个形容词，AI 的输出可能完全不同。
这个附录收录了最常用、最有效的修饰词。
当你不知道怎么描述你想要的风格时，来这里找找灵感。

一、 语气与风格类

正式程度：
非常正式：academic（学术的）、formal（正式的）、professional（专业的）、diplomatic（外交的）
中等正式：business-like（商务的）、polite（礼貌的）、respectful（尊重的）
轻松随意：casual（随意的）、friendly（友好的）、conversational（对话式的）、laid-back（轻松的）
非常随意：informal（非正式的）、chatty（闲聊的）、colloquial（口语的）

情感色彩：
积极：enthusiastic（热情的）、optimistic（乐观的）、encouraging（鼓励的）、uplifting（振奋的）
中性：objective（客观的）、neutral（中立的）、balanced（平衡的）、factual（事实性的）
消极：critical（批判的）、skeptical（怀疑的）、cautious（谨慎的）、pessimistic（悲观的）

幽默程度：
严肃：serious（严肃的）、solemn（庄重的）、grave（严肃的）
轻松：light-hearted（轻松的）、playful（俏皮的）、witty（机智的）
搞笑：humorous（幽默的）、funny（好笑的）、satirical（讽刺的）、sarcastic（挖苦的）

二、 内容密度类

详细程度：
极简：concise（简洁的）、brief（简短的）、to-the-point（直奔主题的）、minimalist（极简的）
适中：balanced（平衡的）、moderate（适度的）、comprehensive（全面的）
详尽：detailed（详细的）、in-depth（深入的）、exhaustive（详尽的）、thorough（彻底的）

复杂程度：
简单：simple（简单的）、easy-to-understand（易懂的）、beginner-friendly（新手友好的）
适中：intermediate（中级的）、accessible（可理解的）
复杂：advanced（高级的）、technical（技术性的）、sophisticated（复杂精妙的）

三、 创意与逻辑类

创意程度：
保守：conventional（传统的）、standard（标准的）、orthodox（正统的）
适中：creative（有创意的）、innovative（创新的）、fresh（新鲜的）
大胆：unconventional（非传统的）、bold（大胆的）、avant-garde（前卫的）、experimental（实验性的）

逻辑严谨度：
松散：free-flowing（自由流动的）、stream-of-consciousness（意识流的）
适中：structured（结构化的）、organized（有组织的）
严谨：rigorous（严谨的）、systematic（系统的）、methodical（有条理的）、logical（逻辑的）

四、 受众定位类

年龄层：
儿童：kid-friendly（儿童友好的）、simple（简单的）、fun（有趣的）
青少年：teen-oriented（面向青少年的）、trendy（时髦的）、relatable（有共鸣的）
成年人：mature（成熟的）、sophisticated（精致的）、professional（专业的）
老年人：senior-friendly（老年友好的）、patient（耐心的）、clear（清晰的）

专业程度：
外行：layman-friendly（外行友好的）、jargon-free（无术语的）、accessible（易理解的）
半专业：semi-technical（半技术性的）、informed（知情的）
专业：expert-level（专家级的）、technical（技术性的）、specialized（专业化的）

五、 文体风格类

叙事风格：
新闻：journalistic（新闻式的）、factual（事实性的）、objective（客观的）
故事：narrative（叙事的）、story-like（故事性的）、engaging（引人入胜的）
说明：expository（说明性的）、instructive（指导性的）、educational（教育性的）
议论：argumentative（论证的）、persuasive（说服性的）、analytical（分析性的）

修辞手法：
直白：straightforward（直白的）、plain（朴素的）、literal（字面的）
修辞：rhetorical（修辞的）、figurative（比喻的）、poetic（诗意的）、metaphorical（隐喻的）

六、 行业特定类

营销文案：
销售导向：sales-oriented（销售导向的）、persuasive（说服性的）、compelling（引人注目的）
品牌导向：brand-focused（品牌聚焦的）、storytelling（讲故事的）、emotional（情感的）

技术文档：
用户手册：user-friendly（用户友好的）、step-by-step（分步的）、illustrated（图解的）
API 文档：technical（技术的）、precise（精确的）、comprehensive（全面的）

学术论文：
理论：theoretical（理论的）、abstract（抽象的）、conceptual（概念的）
实证：empirical（实证的）、data-driven（数据驱动的）、evidence-based（基于证据的）

七、 使用技巧

技巧一：叠加使用
不要只用一个形容词，可以叠加 2-3 个。
例如："请用 professional yet friendly 的语气写一封邮件。"
（专业但友好）

技巧二：对比使用
用"不要 X，要 Y"的句式。
例如："不要 academic，要 conversational。"
（不要学术腔，要对话感）

技巧三：参照使用
直接说"像 XX 一样"。
例如："请用像《纽约时报》一样的风格写新闻。"
（参照知名媒体）

技巧四：反向使用
告诉 AI 不要什么。
例如："不要使用 jargon（术语），不要 verbose（啰嗦）。"
（设定红线）

八、 常见组合推荐

组合一：商务邮件
professional + polite + concise + action-oriented
（专业 + 礼貌 + 简洁 + 行动导向）

组合二：小红书文案
casual + enthusiastic + relatable + emoji-rich
（随意 + 热情 + 有共鸣 + 多表情）

组合三：技术文档
technical + precise + structured + beginner-friendly
（技术性 + 精确 + 结构化 + 新手友好）

组合四：演讲稿
engaging + persuasive + story-driven + inspiring
（引人入胜 + 说服性 + 故事驱动 + 鼓舞人心）

组合五：学术论文
rigorous + evidence-based + objective + formal
（严谨 + 基于证据 + 客观 + 正式）

使用建议：
这个词库不是让你死记硬背的。
而是让你在"词穷"的时候，有个地方可以找灵感。
慢慢地，你会形成自己的"常用词库"。
那时候，你就不需要这个附录了。
因为你已经内化了这些词汇，它们会自然地出现在你的提示词里。


附录 C：提示词工程术语表

【附录 C - 提示词工程术语表】

这是一本"黑话字典"。
在提示词工程的圈子里，有很多专业术语。
如果你不懂这些术语，看技术文章或者和同行交流时，可能会一脸懵逼。
这个附录收录了最常见的 50 个术语，每个都配有通俗解释和实际应用。

A

Agent（智能代理）
定义：能够自主感知环境、做出决策、执行行动的 AI 系统。
通俗解释：不需要你每次都下指令，它能自己规划、自己干活的 AI。
应用：AutoGPT、BabyAGI 都是 Agent 的例子。

API（应用程序接口）
定义：Application Programming Interface，让不同软件之间能互相调用的接口。
通俗解释：AI 的"插座"，你可以通过它把 AI 接入你的应用。
应用：用 OpenAI API 把 ChatGPT 集成到你的网站。

B

BROKE 框架
定义：Background + Role + Objectives + Key Results + Experiment，一种提示词结构。
通俗解释：我们在第 2 章讲的"万能公式"。
应用：写复杂提示词时的标准模板。

C

Chain-of-Thought（思维链）
定义：让 AI 一步步展示推理过程的技巧。
通俗解释：让 AI"把草稿纸给你看"，而不是直接说答案。
应用：在提示词里加"Let's think step by step"。

Context Window（上下文窗口）
定义：AI 一次能"看到"的最大文本长度。
通俗解释：AI 的"短期记忆容量"，超过这个长度，它就会忘记前面的内容。
应用：GPT-4 的上下文窗口是 128k tokens（约 10 万字）。

E

Embedding（嵌入）
定义：把文本转换成数字向量的技术。
通俗解释：把文字变成一串数字，方便计算机处理和搜索。
应用：RAG 系统中，用 Embedding 把文档转成向量存储。

F

Few-Shot Prompting（少样本提示）
定义：在提示词里给 AI 几个例子，让它模仿。
通俗解释：给 AI"抄作业"的机会。
应用：我们在 3.3 节详细讲过。

Fine-Tuning（微调）
定义：用特定数据重新训练模型，让它更适合某个任务。
通俗解释：给 AI"补课"，让它在某个领域变得更专业。
应用：企业用自己的数据微调 GPT，做专属客服。

H

Hallucination（幻觉）
定义：AI 编造不存在的事实。
通俗解释：AI"一本正经地胡说八道"。
应用：问 AI 不存在的人物或事件时，它可能会编故事。

I

Instruction Tuning（指令微调）
定义：专门训练模型遵循指令的能力。
通俗解释：教 AI"听话"。
应用：ChatGPT 就是通过 Instruction Tuning 变得这么听话的。

In-Context Learning（上下文学习）
定义：AI 在对话过程中学习新知识的能力。
通俗解释：你教它一次，它这次对话里就记住了（但下次对话又忘了）。
应用：在对话中给 AI 新定义，它会在后续回答中使用。

L

LangChain
定义：一个开源框架，用于构建基于 LLM 的应用。
通俗解释：搭建 AI Agent 的"乐高积木"。
应用：用 LangChain 快速搭建 RAG 系统或聊天机器人。

LLM（大语言模型）
定义：Large Language Model，用海量文本训练出来的 AI 模型。
通俗解释：ChatGPT、Claude 这些都是 LLM。
应用：几乎所有的提示词工程都是基于 LLM 的。

M

Multimodal（多模态）
定义：能处理多种类型数据（文字、图片、音频、视频）的 AI。
通俗解释：不仅会"说"，还会"看"和"听"的 AI。
应用：GPT-4V、Gemini 都是多模态模型。

N

Negative Prompting（反向提示）
定义：告诉 AI 不要做什么。
通俗解释：给 AI 设"红线"。
应用：我们在 3.5 节讲过，用"不要 XX"来约束 AI。

O

One-Shot Prompting（单样本提示）
定义：只给 AI 一个例子。
通俗解释：比 Few-Shot 更极简，只给一个参考。
应用：当你只有一个好例子时使用。

P

Parameters（参数）
定义：模型内部的"知识"，训练时学到的数字。
通俗解释：AI 的"脑细胞"，参数越多，AI 越聪明（但也越慢、越贵）。
应用：GPT-4 有 1.76 万亿参数。

Plugin（插件）
定义：扩展 AI 能力的外部工具。
通俗解释：给 AI 装的"手和脚"。
应用：ChatGPT 的联网搜索、代码解释器都是插件。

Prompt（提示词）
定义：你给 AI 的指令或问题。
通俗解释：和 AI 说的话。
应用：本书的核心概念。

Prompt Engineering（提示词工程）
定义：设计和优化提示词的技术和艺术。
通俗解释：怎么和 AI 说话才能得到最好的结果。
应用：你正在学的这门手艺。

R

RAG（检索增强生成）
定义：Retrieval-Augmented Generation，让 AI 先搜索资料再回答。
通俗解释：给 AI 装一个"知识库"，让它"开卷考试"。
应用：我们在 7.3 节详细讲过。

Role Prompting（角色提示）
定义：让 AI 扮演某个角色。
通俗解释：告诉 AI"你是一个 XX"。
应用：我们在 3.1 节讲过。

S

System Prompt（系统提示词）
定义：在对话开始前设定的"底层指令"。
通俗解释：AI 的"人设"和"工作守则"。
应用：在 GPTs 或 API 中设定 System Prompt，让 AI 始终遵循某种规则。

T

Temperature（温度）
定义：控制 AI 输出随机性的参数。
通俗解释：温度越高，AI 越"发散"；温度越低，AI 越"保守"。
应用：写创意内容时用高温度（0.8-1.0），写技术文档时用低温度（0.1-0.3）。

Token
定义：AI 处理文本的最小单位。
通俗解释：大概 1 个 token = 0.75 个英文单词 = 1.5 个中文字。
应用：API 按 token 收费，上下文窗口也按 token 计算。

Tool Use（工具调用）
定义：AI 调用外部工具（如搜索、计算器、数据库）的能力。
通俗解释：AI 不仅会"说"，还会"做"。
应用：Agent 的核心能力之一。

V

Vector Database（向量数据库）
定义：专门存储和搜索向量的数据库。
通俗解释：RAG 系统的"仓库"，用来存文档的数字化版本。
应用：Pinecone、Weaviate 都是向量数据库。

Z

Zero-Shot Prompting（零样本提示）
定义：不给任何例子，直接让 AI 做任务。
通俗解释：直接下命令，不给参考。
应用：最简单的提示词方式，但效果可能不如 Few-Shot。

术语使用建议：
这些术语不是让你装逼用的。
而是让你在学习和交流时，能更高效地理解和表达。
当你看到一篇技术文章提到"RAG + Few-Shot + CoT"时，你能立刻知道它在说什么。
当你和同行讨论时，你能用专业术语精准表达你的想法。
但记住：在和普通用户交流时，少用术语，多说人话。
术语是工具，不是炫耀的资本。

全书完。
